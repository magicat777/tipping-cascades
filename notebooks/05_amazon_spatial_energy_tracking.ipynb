{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Amazon Spatial Model with Energy-Constrained Tipping Cascades\n",
    "\n",
    "**Author:** Jason Holt  \n",
    "**Date:** December 2025\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook applies the energy-constrained tipping cascade framework to **spatially-explicit Amazon moisture recycling data** provided by Dr. Arie Staal (Utrecht University).\n",
    "\n",
    "### Data Source\n",
    "\n",
    "- **Dataset**: Amazon Adaptation Model (1° resolution)\n",
    "- **Reference**: Wunderling et al. (2022) PNAS, https://doi.org/10.1073/pnas.2120777119\n",
    "- **Provider**: Dr. Arie Staal, Utrecht University\n",
    "- **Figshare**: https://figshare.com/articles/software/Amazon_Adaptation_Model/20089331\n",
    "\n",
    "### Key Questions\n",
    "\n",
    "1. How does moisture recycling create **spatial coupling** between Amazon grid cells?\n",
    "2. Can we track **energy flow** through the moisture recycling network?\n",
    "3. Does the **Lévy tunneling effect** apply to spatially-explicit cascades?\n",
    "4. Which regions are most **thermodynamically vulnerable** to cascade propagation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# Path setup for k3s vs local\n",
    "k3s_path = Path('/opt/research-local/src')\n",
    "local_path = Path.cwd().parent / 'src'\n",
    "\n",
    "if k3s_path.exists():\n",
    "    sys.path.insert(0, str(k3s_path))\n",
    "    project_root = Path('/opt/research-local')\n",
    "    data_root = Path('/opt/research-local/data/amazon/amazon_adaptation_model')\n",
    "    print(\"Running in k3s JupyterLab pod\")\n",
    "else:\n",
    "    sys.path.insert(0, str(local_path))\n",
    "    project_root = Path.cwd().parent\n",
    "    data_root = project_root / 'data' / 'amazon' / 'amazon_adaptation_model'\n",
    "    print(\"Running locally\")\n",
    "\n",
    "# Check data availability\n",
    "if data_root.exists():\n",
    "    print(f\"Data found at: {data_root}\")\n",
    "else:\n",
    "    print(f\"WARNING: Data not found at {data_root}\")\n",
    "    print(\"Please download from: https://figshare.com/articles/software/Amazon_Adaptation_Model/20089331\")\n",
    "\n",
    "# Import energy-constrained module\n",
    "from energy_constrained import (\n",
    "    EnergyConstrainedCusp,\n",
    "    EnergyConstrainedNetwork,\n",
    "    GradientDrivenCoupling,\n",
    "    energy_constrained_euler_maruyama,\n",
    "    EnergyAnalyzer,\n",
    ")\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"\\nEnergy-constrained module loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-netcdf",
   "metadata": {},
   "outputs": [],
   "source": "# Load netCDF data\ntry:\n    from netCDF4 import Dataset\n    NETCDF_AVAILABLE = True\nexcept ImportError:\n    print(\"netCDF4 not available, trying xarray...\")\n    try:\n        import xarray as xr\n        NETCDF_AVAILABLE = False\n    except ImportError:\n        raise ImportError(\"Please install netCDF4 or xarray: pip install netCDF4 xarray\")\n\n# Load sample data file\nsample_file = data_root / 'average_network' / 'era5_new_network_data' / '1deg_2010_01.nc'\n\nif NETCDF_AVAILABLE:\n    ds = Dataset(sample_file)\n    lat_raw = ds.variables['lat'][:]\n    lon_raw = ds.variables['lon'][:]\n    rain_raw = ds.variables['rain'][:]\n    evap_raw = ds.variables['evap'][:]\n    network_raw = ds.variables['network'][:, :]\n    ds.close()\n    \n    # Convert MaskedArrays to regular numpy arrays (fill masked values)\n    # This prevents warnings from numpy operations on masked data\n    lat = np.ma.filled(lat_raw, np.nan) if hasattr(lat_raw, 'mask') else np.asarray(lat_raw)\n    lon = np.ma.filled(lon_raw, np.nan) if hasattr(lon_raw, 'mask') else np.asarray(lon_raw)\n    rain = np.ma.filled(rain_raw, 0.0) if hasattr(rain_raw, 'mask') else np.asarray(rain_raw)\n    evap = np.ma.filled(evap_raw, 0.0) if hasattr(evap_raw, 'mask') else np.asarray(evap_raw)\n    network = np.ma.filled(network_raw, 0.0) if hasattr(network_raw, 'mask') else np.asarray(network_raw)\nelse:\n    ds = xr.open_dataset(sample_file)\n    lat = ds['lat'].values\n    lon = ds['lon'].values\n    rain = ds['rain'].values\n    evap = ds['evap'].values\n    network = ds['network'].values\n    ds.close()\n\nprint(f\"Loaded data for January 2010\")\nprint(f\"  Grid cells: {len(lat)}\")\nprint(f\"  Network shape: {network.shape}\")\nprint(f\"  Lat range: [{np.nanmin(lat):.1f}, {np.nanmax(lat):.1f}]\")\nprint(f\"  Lon range: [{np.nanmin(lon):.1f}, {np.nanmax(lon):.1f}]\")\nprint(f\"  Rain range: [{rain.min():.1f}, {rain.max():.1f}] mm\")\nprint(f\"  Evap range: [{evap.min():.1f}, {evap.max():.1f}] mm\")"
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "## 2. Visualize the Moisture Recycling Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze network structure\n",
    "print(\"Moisture Recycling Network Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Non-zero connections\n",
    "n_connections = np.count_nonzero(network)\n",
    "n_possible = network.shape[0] * network.shape[1] - network.shape[0]  # Exclude diagonal\n",
    "density = n_connections / n_possible\n",
    "\n",
    "print(f\"Total grid cells: {network.shape[0]}\")\n",
    "print(f\"Non-zero connections: {n_connections}\")\n",
    "print(f\"Network density: {density:.4f}\")\n",
    "\n",
    "# Connection strength distribution\n",
    "nonzero_values = network[network > 0]\n",
    "print(f\"\\nMoisture flow (mm/month) statistics:\")\n",
    "print(f\"  Min: {nonzero_values.min():.2f}\")\n",
    "print(f\"  Max: {nonzero_values.max():.2f}\")\n",
    "print(f\"  Mean: {nonzero_values.mean():.2f}\")\n",
    "print(f\"  Median: {np.median(nonzero_values):.2f}\")\n",
    "\n",
    "# In-degree and out-degree\n",
    "in_degree = np.sum(network > 0, axis=0)  # Columns: moisture received\n",
    "out_degree = np.sum(network > 0, axis=1)  # Rows: moisture sent\n",
    "\n",
    "print(f\"\\nDegree statistics:\")\n",
    "print(f\"  Mean in-degree: {in_degree.mean():.1f}\")\n",
    "print(f\"  Mean out-degree: {out_degree.mean():.1f}\")\n",
    "print(f\"  Max in-degree: {in_degree.max()}\")\n",
    "print(f\"  Max out-degree: {out_degree.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-spatial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# 1. Rainfall map\n",
    "ax1 = axes[0, 0]\n",
    "sc1 = ax1.scatter(lon, lat, c=rain, cmap='Blues', s=5, alpha=0.8)\n",
    "ax1.set_xlabel('Longitude')\n",
    "ax1.set_ylabel('Latitude')\n",
    "ax1.set_title('Rainfall (mm/month)')\n",
    "plt.colorbar(sc1, ax=ax1)\n",
    "\n",
    "# 2. Evapotranspiration map\n",
    "ax2 = axes[0, 1]\n",
    "sc2 = ax2.scatter(lon, lat, c=evap, cmap='Greens', s=5, alpha=0.8)\n",
    "ax2.set_xlabel('Longitude')\n",
    "ax2.set_ylabel('Latitude')\n",
    "ax2.set_title('Evapotranspiration (mm/month)')\n",
    "plt.colorbar(sc2, ax=ax2)\n",
    "\n",
    "# 3. In-degree (moisture received)\n",
    "ax3 = axes[1, 0]\n",
    "sc3 = ax3.scatter(lon, lat, c=in_degree, cmap='YlOrRd', s=5, alpha=0.8)\n",
    "ax3.set_xlabel('Longitude')\n",
    "ax3.set_ylabel('Latitude')\n",
    "ax3.set_title('In-Degree (# sources)')\n",
    "plt.colorbar(sc3, ax=ax3)\n",
    "\n",
    "# 4. Out-degree (moisture sent)\n",
    "ax4 = axes[1, 1]\n",
    "sc4 = ax4.scatter(lon, lat, c=out_degree, cmap='YlOrRd', s=5, alpha=0.8)\n",
    "ax4.set_xlabel('Longitude')\n",
    "ax4.set_ylabel('Latitude')\n",
    "ax4.set_title('Out-Degree (# destinations)')\n",
    "plt.colorbar(sc4, ax=ax4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey observation: Western Amazon has high in-degree (receives moisture)\")\n",
    "print(\"Eastern/coastal areas have high out-degree (moisture sources)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-histogram",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network structure histograms\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Moisture flow distribution (log scale)\n",
    "ax1 = axes[0]\n",
    "ax1.hist(nonzero_values, bins=50, color='blue', alpha=0.7, edgecolor='black')\n",
    "ax1.set_xlabel('Moisture Flow (mm/month)')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Moisture Flow Distribution')\n",
    "ax1.set_yscale('log')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# In-degree distribution\n",
    "ax2 = axes[1]\n",
    "ax2.hist(in_degree, bins=30, color='orange', alpha=0.7, edgecolor='black')\n",
    "ax2.set_xlabel('In-Degree')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_title('In-Degree Distribution')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Out-degree distribution\n",
    "ax3 = axes[2]\n",
    "ax3.hist(out_degree, bins=30, color='green', alpha=0.7, edgecolor='black')\n",
    "ax3.set_xlabel('Out-Degree')\n",
    "ax3.set_ylabel('Count')\n",
    "ax3.set_title('Out-Degree Distribution')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subnetwork-header",
   "metadata": {},
   "source": [
    "## 3. Create Energy-Constrained Subnetwork\n",
    "\n",
    "The full 567-cell network is computationally expensive. We'll create a representative subnetwork of the most connected cells for energy tracking experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-subnetwork",
   "metadata": {},
   "outputs": [],
   "source": "def create_amazon_subnetwork(network, lat, lon, rain, evap, n_cells=50, min_flow=5.0):\n    \"\"\"\n    Create an energy-constrained subnetwork from the Amazon moisture recycling data.\n    \n    Parameters\n    ----------\n    network : ndarray\n        Full moisture recycling matrix (567x567)\n    lat, lon : ndarray\n        Coordinates\n    rain, evap : ndarray\n        Rainfall and evapotranspiration\n    n_cells : int\n        Number of cells to include in subnetwork\n    min_flow : float\n        Minimum moisture flow to include coupling (mm/month)\n    \n    Returns\n    -------\n    EnergyConstrainedNetwork\n        Subnetwork with energy tracking\n    \"\"\"\n    # Convert MaskedArrays to regular arrays (fill masked values with 0)\n    network_arr = np.ma.filled(network, 0) if hasattr(network, 'mask') else np.asarray(network)\n    lat_arr = np.ma.filled(lat, np.nan) if hasattr(lat, 'mask') else np.asarray(lat)\n    lon_arr = np.ma.filled(lon, np.nan) if hasattr(lon, 'mask') else np.asarray(lon)\n    rain_arr = np.ma.filled(rain, 0) if hasattr(rain, 'mask') else np.asarray(rain)\n    evap_arr = np.ma.filled(evap, 0) if hasattr(evap, 'mask') else np.asarray(evap)\n    \n    # Select cells with highest total moisture flow (in + out)\n    total_flow = np.sum(network_arr, axis=0) + np.sum(network_arr, axis=1)\n    top_indices = np.argsort(total_flow)[-n_cells:]\n    \n    # Create subnetwork\n    sub_network = network_arr[np.ix_(top_indices, top_indices)]\n    sub_lat = lat_arr[top_indices]\n    sub_lon = lon_arr[top_indices]\n    sub_rain = rain_arr[top_indices]\n    sub_evap = evap_arr[top_indices]\n    \n    # Create energy-constrained network\n    net = EnergyConstrainedNetwork()\n    \n    # Add elements\n    for i in range(n_cells):\n        # Use rain/evap ratio as proxy for forest state\n        # Higher ratio = more stable forest\n        ratio = sub_rain[i] / (sub_evap[i] + 1e-6)\n        \n        # Scale barrier height by stability\n        barrier = 0.3 + 0.4 * min(ratio / 2.0, 1.0)  # Range [0.3, 0.7]\n        \n        # Dissipation rate inversely related to forest health\n        dissipation = 0.05 + 0.1 * (1 - min(ratio / 2.0, 1.0))\n        \n        element = EnergyConstrainedCusp(\n            a=-1, b=1, c=0,\n            E_stable=0.0,\n            E_tipped=1.0,\n            barrier_height=barrier,\n            dissipation_rate=dissipation,\n            heat_capacity=1.0\n        )\n        \n        # Store metadata\n        element.lat = sub_lat[i]\n        element.lon = sub_lon[i]\n        element.rain = sub_rain[i]\n        element.evap = sub_evap[i]\n        element.original_idx = top_indices[i]\n        \n        net.add_element(f'cell_{i}', element)\n    \n    # Add couplings based on moisture flow\n    n_couplings = 0\n    for i in range(n_cells):\n        for j in range(n_cells):\n            if i != j and sub_network[i, j] > min_flow:\n                # Coupling strength proportional to moisture flow\n                # Normalize by typical flow magnitude\n                strength = sub_network[i, j] / 100.0  # Scale factor\n                \n                coupling = GradientDrivenCoupling(conductivity=strength)\n                net.add_coupling(f'cell_{j}', f'cell_{i}', coupling)  # j sends to i\n                n_couplings += 1\n    \n    print(f\"Created subnetwork:\")\n    print(f\"  Cells: {n_cells}\")\n    print(f\"  Couplings: {n_couplings}\")\n    print(f\"  Density: {n_couplings / (n_cells * (n_cells - 1)):.3f}\")\n    \n    return net, top_indices, sub_lat, sub_lon\n\n# Create subnetwork\namazon_net, selected_indices, sub_lat, sub_lon = create_amazon_subnetwork(\n    network, lat, lon, rain, evap, n_cells=50, min_flow=5.0\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-subnetwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize selected cells\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# All cells (gray)\n",
    "ax.scatter(lon, lat, c='lightgray', s=3, alpha=0.5, label='All cells')\n",
    "\n",
    "# Selected cells (colored by barrier height)\n",
    "barriers = [amazon_net.get_element(f'cell_{i}').barrier_height for i in range(50)]\n",
    "sc = ax.scatter(sub_lon, sub_lat, c=barriers, cmap='RdYlGn', s=50, \n",
    "                edgecolor='black', linewidth=0.5, label='Subnetwork')\n",
    "\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_title('Amazon Subnetwork (colored by barrier height = stability)')\n",
    "plt.colorbar(sc, label='Barrier Height')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sim-header",
   "metadata": {},
   "source": [
    "## 4. Run Energy-Tracked Cascade Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation with energy tracking\n",
    "y0 = amazon_net.get_initial_state()\n",
    "print(f\"Initial state shape: {y0.shape}\")\n",
    "print(f\"  State variables: {amazon_net.n_elements}\")\n",
    "print(f\"  Energy variables: {amazon_net.n_elements}\")\n",
    "\n",
    "# Simulation parameters\n",
    "duration = 500.0\n",
    "dt = 0.5\n",
    "sigma = 0.06  # Moderate noise\n",
    "alpha = 1.8   # Slightly heavy-tailed (between Gaussian and Lévy)\n",
    "\n",
    "print(f\"\\nSimulation parameters:\")\n",
    "print(f\"  Duration: {duration}\")\n",
    "print(f\"  dt: {dt}\")\n",
    "print(f\"  Noise: σ={sigma}, α={alpha}\")\n",
    "\n",
    "# Run\n",
    "result = energy_constrained_euler_maruyama(\n",
    "    f_extended=amazon_net.f_extended,\n",
    "    y0=y0,\n",
    "    t_span=(0, duration),\n",
    "    dt=dt,\n",
    "    sigma=sigma * np.ones(amazon_net.n_elements),\n",
    "    alpha=alpha * np.ones(amazon_net.n_elements)\n",
    ")\n",
    "\n",
    "print(f\"\\nSimulation complete!\")\n",
    "print(f\"  Time points: {len(result.t)}\")\n",
    "print(f\"  Final tipped cells: {np.sum(result.x[-1] > 0)} / {amazon_net.n_elements}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12), sharex=True)\n",
    "\n",
    "# 1. State evolution (sample cells)\n",
    "ax1 = axes[0]\n",
    "sample_cells = [0, 10, 20, 30, 40]\n",
    "for i in sample_cells:\n",
    "    ax1.plot(result.t, result.x[:, i], alpha=0.7, linewidth=0.8, label=f'Cell {i}')\n",
    "ax1.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "ax1.set_ylabel('State')\n",
    "ax1.set_title('Sample Cell States Over Time')\n",
    "ax1.legend(loc='upper right', ncol=5)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Fraction tipped over time\n",
    "ax2 = axes[1]\n",
    "frac_tipped = np.mean(result.x > 0, axis=1)\n",
    "ax2.plot(result.t, frac_tipped * 100, 'r-', linewidth=2)\n",
    "ax2.set_ylabel('% Tipped')\n",
    "ax2.set_title('Cascade Propagation')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Total system energy\n",
    "ax3 = axes[2]\n",
    "E_total = np.sum(result.E, axis=1)\n",
    "ax3.plot(result.t, E_total, 'g-', linewidth=2)\n",
    "ax3.set_xlabel('Time')\n",
    "ax3.set_ylabel('Total Energy')\n",
    "ax3.set_title('System Energy Evolution')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-cascade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial cascade visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Snapshots at different times\n",
    "times = [0, 100, 200, 300, 400, 499]\n",
    "time_indices = [int(t / dt) for t in times]\n",
    "\n",
    "for ax, t_idx, t_val in zip(axes.flat, time_indices, times):\n",
    "    states = result.x[t_idx, :]\n",
    "    \n",
    "    # Color by state: green = stable, red = tipped\n",
    "    colors = ['green' if s < 0 else 'red' for s in states]\n",
    "    \n",
    "    ax.scatter(sub_lon, sub_lat, c=colors, s=50, edgecolor='black', linewidth=0.5)\n",
    "    ax.set_title(f't = {t_val}')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    \n",
    "    n_tipped = np.sum(states > 0)\n",
    "    ax.text(0.02, 0.98, f'{n_tipped}/50 tipped', transform=ax.transAxes,\n",
    "            verticalalignment='top', fontsize=10,\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.suptitle('Spatial Cascade Propagation', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis-header",
   "metadata": {},
   "source": [
    "## 5. Thermodynamic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermo-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute thermodynamic metrics\n",
    "analyzer = EnergyAnalyzer(amazon_net, result)\n",
    "budget = analyzer.compute_energy_budget()\n",
    "\n",
    "print(\"Thermodynamic Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Total entropy produced\n",
    "total_entropy = analyzer.compute_total_entropy_produced()\n",
    "print(f\"Total entropy produced: {total_entropy:.2f}\")\n",
    "\n",
    "# Tipping events\n",
    "events = analyzer.identify_tipping_events()\n",
    "tip_events = [e for e in events if e.direction == 'tip']\n",
    "recover_events = [e for e in events if e.direction == 'recover']\n",
    "\n",
    "print(f\"\\nTipping events: {len(tip_events)}\")\n",
    "print(f\"Recovery events: {len(recover_events)}\")\n",
    "\n",
    "# Energy costs\n",
    "if events:\n",
    "    costs = analyzer.compute_cascade_energy_costs(events)\n",
    "    print(f\"\\nAverage entropy per event: {costs['average_entropy_per_event']:.4f}\")\n",
    "    if costs['n_tip_events'] > 0:\n",
    "        print(f\"Tip event entropy (mean): {costs['tip_entropy_avg']:.4f}\")\n",
    "    if costs['n_recover_events'] > 0:\n",
    "        print(f\"Recovery event entropy (mean): {costs['recover_entropy_avg']:.4f}\")\n",
    "    \n",
    "    if costs['tip_entropy_avg'] > 0 and costs['recover_entropy_avg'] > 0:\n",
    "        ratio = costs['tip_entropy_avg'] / costs['recover_entropy_avg']\n",
    "        print(f\"\\nTip/Recovery ratio: {ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entropy-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy production visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Entropy production rate over time\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(result.t, budget.entropy_production, 'g-', alpha=0.8)\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Entropy Production Rate')\n",
    "ax1.set_title('Entropy Production Over Time')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Cumulative entropy\n",
    "ax2 = axes[0, 1]\n",
    "cumulative_entropy = np.cumsum(budget.entropy_production) * dt\n",
    "ax2.plot(result.t, cumulative_entropy, 'b-', linewidth=2)\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Cumulative Entropy')\n",
    "ax2.set_title('Cumulative Entropy Production')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Energy per cell (final state)\n",
    "ax3 = axes[1, 0]\n",
    "final_E = result.E[-1, :]\n",
    "colors = ['red' if result.x[-1, i] > 0 else 'green' for i in range(50)]\n",
    "ax3.scatter(sub_lon, sub_lat, c=final_E, cmap='coolwarm', s=50, \n",
    "            edgecolor='black', linewidth=0.5)\n",
    "ax3.set_xlabel('Longitude')\n",
    "ax3.set_ylabel('Latitude')\n",
    "ax3.set_title('Final Energy Distribution')\n",
    "plt.colorbar(ax3.collections[0], ax=ax3, label='Energy')\n",
    "\n",
    "# 4. Time in tipped state per cell\n",
    "ax4 = axes[1, 1]\n",
    "time_tipped = np.mean(result.x > 0, axis=0) * 100\n",
    "sc = ax4.scatter(sub_lon, sub_lat, c=time_tipped, cmap='RdYlGn_r', s=50,\n",
    "                 edgecolor='black', linewidth=0.5)\n",
    "ax4.set_xlabel('Longitude')\n",
    "ax4.set_ylabel('Latitude')\n",
    "ax4.set_title('% Time in Tipped State')\n",
    "plt.colorbar(sc, ax=ax4, label='% Tipped')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerability-header",
   "metadata": {},
   "source": [
    "## 6. Identify Thermodynamically Vulnerable Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute vulnerability metrics for each cell\n",
    "vulnerability_metrics = []\n",
    "\n",
    "for i in range(amazon_net.n_elements):\n",
    "    element = amazon_net.get_element(f'cell_{i}')\n",
    "    \n",
    "    # Time spent tipped\n",
    "    time_tipped_pct = np.mean(result.x[:, i] > 0) * 100\n",
    "    \n",
    "    # Average state (closer to 0 = more vulnerable)\n",
    "    avg_state = np.mean(result.x[:, i])\n",
    "    \n",
    "    # State variance (high variance = unstable)\n",
    "    state_var = np.var(result.x[:, i])\n",
    "    \n",
    "    # Barrier height (low = vulnerable)\n",
    "    barrier = element.barrier_height\n",
    "    \n",
    "    # Composite vulnerability score\n",
    "    vulnerability = (time_tipped_pct / 100) * 0.4 + (1 - barrier) * 0.3 + min(state_var, 1) * 0.3\n",
    "    \n",
    "    vulnerability_metrics.append({\n",
    "        'cell': i,\n",
    "        'lat': element.lat,\n",
    "        'lon': element.lon,\n",
    "        'time_tipped': time_tipped_pct,\n",
    "        'avg_state': avg_state,\n",
    "        'state_var': state_var,\n",
    "        'barrier': barrier,\n",
    "        'vulnerability': vulnerability\n",
    "    })\n",
    "\n",
    "# Sort by vulnerability\n",
    "vulnerability_metrics.sort(key=lambda x: x['vulnerability'], reverse=True)\n",
    "\n",
    "print(\"Most Vulnerable Cells\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Cell':>6} {'Lat':>8} {'Lon':>8} {'%Tipped':>8} {'Barrier':>8} {'Vuln':>8}\")\n",
    "print(\"-\" * 70)\n",
    "for m in vulnerability_metrics[:10]:\n",
    "    print(f\"{m['cell']:>6} {m['lat']:>8.2f} {m['lon']:>8.2f} {m['time_tipped']:>8.1f} {m['barrier']:>8.3f} {m['vulnerability']:>8.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerability-map",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vulnerability map\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "vuln_scores = [m['vulnerability'] for m in vulnerability_metrics]\n",
    "vuln_lons = [m['lon'] for m in vulnerability_metrics]\n",
    "vuln_lats = [m['lat'] for m in vulnerability_metrics]\n",
    "\n",
    "# Background: all Amazon cells\n",
    "ax.scatter(lon, lat, c='lightgray', s=3, alpha=0.3)\n",
    "\n",
    "# Subnetwork colored by vulnerability\n",
    "sc = ax.scatter(vuln_lons, vuln_lats, c=vuln_scores, cmap='RdYlGn_r', \n",
    "                s=80, edgecolor='black', linewidth=0.5, vmin=0, vmax=1)\n",
    "\n",
    "# Mark top 5 most vulnerable\n",
    "for i, m in enumerate(vulnerability_metrics[:5]):\n",
    "    ax.annotate(f\"{i+1}\", (m['lon'], m['lat']), fontsize=12, fontweight='bold',\n",
    "                ha='center', va='center', color='white')\n",
    "\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_title('Thermodynamic Vulnerability Map\\n(Red = Most Vulnerable)')\n",
    "plt.colorbar(sc, label='Vulnerability Score')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Red cells: Low barrier height + frequently tipped = cascade initiation points\")\n",
    "print(\"- Green cells: High barrier + rarely tipped = resilient regions\")\n",
    "print(\"- These vulnerability patterns can inform conservation priorities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Moisture recycling creates spatial coupling** between Amazon grid cells, enabling cascade propagation\n",
    "\n",
    "2. **Energy tracking reveals thermodynamic costs** of tipping and recovery in spatially-explicit models\n",
    "\n",
    "3. **Vulnerability mapping** identifies regions most susceptible to cascade initiation\n",
    "\n",
    "### Data Citation\n",
    "\n",
    "Amazon moisture recycling data provided by:\n",
    "\n",
    "> Wunderling, N., Staal, A., Sakschewski, B., Hirota, M., Tuinenburg, O. A., Donges, J. F., Barbosa, H. M. J., & Winkelmann, R. (2022). Recurrent droughts increase risk of cascading tipping events by outpacing adaptive capacities in the Amazon rainforest. *PNAS*, 119(32), e2120777119. https://doi.org/10.1073/pnas.2120777119\n",
    "\n",
    "Data access: https://figshare.com/articles/software/Amazon_Adaptation_Model/20089331\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Full network analysis**: Scale to all 567 cells using distributed computing\n",
    "2. **Drought scenarios**: Test cascade response under 2005, 2010, 2015 drought conditions\n",
    "3. **Lévy vs Gaussian**: Compare noise-type effects in spatial model\n",
    "4. **Deforestation scenarios**: Model impact of land-use change on cascade vulnerability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Amazon Spatial Energy-Tracking Analysis Complete!\")\n",
    "print(\"\\nData citation: Wunderling et al. (2022) PNAS\")\n",
    "print(\"Data provided by: Dr. Arie Staal, Utrecht University\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v0pol2vxczo",
   "source": "## 8. Experiment: Lévy vs Gaussian Noise in Spatial Model\n\nThis experiment tests whether the **noise-type bifurcation** discovered in Phase 3 applies to spatially-explicit Amazon cascades.\n\n### Phase 3 Key Findings (to test in spatial model):\n1. **High Lévy noise**: Tipping costs 1700x more entropy than recovery (catastrophic jumps)\n2. **Low Lévy noise**: Tipping costs LESS than recovery (inverted - \"tunneling\" effect)\n3. **Gaussian noise**: Classical Kramers barrier-crossing dynamics\n\n### Hypotheses for Spatial Model:\n- **H1**: Lévy noise enables faster cascade propagation (barrier bypass via extreme jumps)\n- **H2**: Gaussian noise produces more localized, gradual cascades\n- **H3**: The tip/recovery entropy asymmetry persists in spatial networks",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "yga26a69b3e",
   "source": "# Configure Lévy vs Gaussian comparison\n# Using the same 50-cell Amazon subnetwork (amazon_net) from earlier\n\nnoise_configs = [\n    {'label': 'Gaussian (α=2.0)', 'sigma': 0.06, 'alpha': 2.0, 'color': 'blue'},\n    {'label': 'Lévy α=1.8', 'sigma': 0.06, 'alpha': 1.8, 'color': 'orange'},\n    {'label': 'Lévy α=1.5', 'sigma': 0.06, 'alpha': 1.5, 'color': 'red'},\n    {'label': 'Lévy α=1.2 (heavy tail)', 'sigma': 0.06, 'alpha': 1.2, 'color': 'darkred'},\n]\n\n# Simulation parameters (same as baseline run)\nduration_compare = 500.0\ndt_compare = 0.5\nn_runs_compare = 5  # Ensemble for statistics\n\nprint(\"Lévy vs Gaussian Spatial Comparison\")\nprint(\"=\" * 60)\nprint(f\"Network: 50-cell Amazon subnetwork\")\nprint(f\"Duration: {duration_compare} time units\")\nprint(f\"Ensemble size: {n_runs_compare} runs per configuration\")\nprint(f\"\\nNoise configurations:\")\nfor cfg in noise_configs:\n    print(f\"  {cfg['label']}: σ={cfg['sigma']}, α={cfg['alpha']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "1r60edaszo5",
   "source": "# Run ensembles for each noise configuration\nfrom energy_constrained.solvers import run_ensemble\nfrom energy_constrained.analysis import analyze_ensemble_thermodynamics\n\nspatial_noise_results = {}\n\nfor cfg in noise_configs:\n    label = cfg['label']\n    print(f\"\\n{'='*60}\")\n    print(f\"Running: {label}\")\n    print('='*60)\n    \n    # Get initial state\n    y0 = amazon_net.get_initial_state()\n    \n    # Run ensemble\n    results = run_ensemble(\n        amazon_net,\n        n_runs=n_runs_compare,\n        duration=duration_compare,\n        dt=dt_compare,\n        sigma=cfg['sigma'],\n        alpha=cfg['alpha'],\n        seed=42,\n        progress=True\n    )\n    \n    # Analyze thermodynamics\n    thermo = analyze_ensemble_thermodynamics(amazon_net, results)\n    \n    spatial_noise_results[label] = {\n        'config': cfg,\n        'results': results,\n        'thermo': thermo\n    }\n    \n    # Quick summary\n    print(f\"\\nResults for {label}:\")\n    print(f\"  Total entropy: {thermo['total_entropy']['mean']:.1f} ± {thermo['total_entropy']['std']:.1f}\")\n    print(f\"  Tipping events: {thermo['n_tip_events']['mean']:.1f} ± {thermo['n_tip_events']['std']:.1f}\")\n    print(f\"  Mean time tipped: {100*np.mean(thermo['element_time_tipped']['mean']):.1f}%\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"All noise configurations complete!\")\nprint(\"=\"*60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "grla3yzy9rh",
   "source": "# Compare cascade propagation dynamics\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# 1. Cascade propagation (% tipped over time) - ensemble mean\nax1 = axes[0, 0]\nfor label, data in spatial_noise_results.items():\n    cfg = data['config']\n    results = data['results']\n    \n    # Compute mean % tipped across ensemble\n    frac_tipped_all = []\n    for r in results:\n        frac_tipped = np.mean(r.x > 0, axis=1) * 100\n        frac_tipped_all.append(frac_tipped)\n    \n    mean_tipped = np.mean(frac_tipped_all, axis=0)\n    std_tipped = np.std(frac_tipped_all, axis=0)\n    t = results[0].t\n    \n    ax1.plot(t, mean_tipped, color=cfg['color'], linewidth=2, label=label)\n    ax1.fill_between(t, mean_tipped - std_tipped, mean_tipped + std_tipped, \n                     color=cfg['color'], alpha=0.2)\n\nax1.set_xlabel('Time')\nax1.set_ylabel('% Cells Tipped')\nax1.set_title('Cascade Propagation: Lévy vs Gaussian')\nax1.legend(loc='lower right')\nax1.grid(True, alpha=0.3)\n\n# 2. Total entropy production comparison\nax2 = axes[0, 1]\nlabels = list(spatial_noise_results.keys())\ncolors = [spatial_noise_results[l]['config']['color'] for l in labels]\nentropy_means = [spatial_noise_results[l]['thermo']['total_entropy']['mean'] for l in labels]\nentropy_stds = [spatial_noise_results[l]['thermo']['total_entropy']['std'] for l in labels]\n\nbars = ax2.bar(range(len(labels)), entropy_means, yerr=entropy_stds, \n               color=colors, alpha=0.7, capsize=5)\nax2.set_xticks(range(len(labels)))\nax2.set_xticklabels([l.replace(' ', '\\n') for l in labels], fontsize=9)\nax2.set_ylabel('Total Entropy Produced')\nax2.set_title('Entropy Production by Noise Type')\nax2.grid(True, alpha=0.3, axis='y')\n\n# 3. Number of tipping events\nax3 = axes[1, 0]\ntip_means = [spatial_noise_results[l]['thermo']['n_tip_events']['mean'] for l in labels]\ntip_stds = [spatial_noise_results[l]['thermo']['n_tip_events']['std'] for l in labels]\n\nbars = ax3.bar(range(len(labels)), tip_means, yerr=tip_stds,\n               color=colors, alpha=0.7, capsize=5)\nax3.set_xticks(range(len(labels)))\nax3.set_xticklabels([l.replace(' ', '\\n') for l in labels], fontsize=9)\nax3.set_ylabel('Number of Tipping Events')\nax3.set_title('Tipping Event Frequency')\nax3.grid(True, alpha=0.3, axis='y')\n\n# 4. System energy evolution comparison\nax4 = axes[1, 1]\nfor label, data in spatial_noise_results.items():\n    cfg = data['config']\n    results = data['results']\n    \n    # Mean energy across ensemble\n    E_all = [np.sum(r.E, axis=1) for r in results]\n    E_mean = np.mean(E_all, axis=0)\n    t = results[0].t\n    \n    ax4.plot(t, E_mean, color=cfg['color'], linewidth=2, label=label)\n\nax4.set_xlabel('Time')\nax4.set_ylabel('Total System Energy')\nax4.set_title('Energy Accumulation')\nax4.legend(loc='lower right')\nax4.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "k8c8scbnvb",
   "source": "# Compare spatial patterns at end of simulation\nfig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\nfor ax, (label, data) in zip(axes.flat, spatial_noise_results.items()):\n    cfg = data['config']\n    results = data['results']\n    \n    # Compute mean time tipped per cell across ensemble\n    time_tipped_all = []\n    for r in results:\n        time_tipped = np.mean(r.x > 0, axis=0) * 100\n        time_tipped_all.append(time_tipped)\n    \n    mean_time_tipped = np.mean(time_tipped_all, axis=0)\n    \n    # Plot spatial distribution\n    sc = ax.scatter(sub_lon, sub_lat, c=mean_time_tipped, cmap='RdYlGn_r', \n                    s=60, edgecolor='black', linewidth=0.5, vmin=0, vmax=100)\n    \n    # Background Amazon\n    ax.scatter(lon, lat, c='lightgray', s=2, alpha=0.2)\n    \n    ax.set_xlabel('Longitude')\n    ax.set_ylabel('Latitude')\n    ax.set_title(f'{label}\\nMean: {np.mean(mean_time_tipped):.1f}% tipped')\n    plt.colorbar(sc, ax=ax, label='% Time Tipped')\n\nplt.suptitle('Spatial Tipping Patterns by Noise Type', fontsize=14, y=1.02)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nKey question: Do different noise types produce different spatial cascade patterns?\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "pcgw9lxk0c9",
   "source": "# Analyze tip/recovery entropy asymmetry for each noise type\n# This tests whether the \"noise-type bifurcation\" from Phase 3 applies to spatial models\n\nprint(\"Tip vs Recovery Entropy Analysis\")\nprint(\"=\" * 60)\n\nentropy_asymmetry_results = {}\n\nfor label, data in spatial_noise_results.items():\n    cfg = data['config']\n    results = data['results']\n    \n    tip_entropies = []\n    recover_entropies = []\n    \n    for result in results:\n        analyzer = EnergyAnalyzer(amazon_net, result)\n        events = analyzer.identify_tipping_events()\n        \n        if events:\n            costs = analyzer.compute_cascade_energy_costs(events)\n            \n            if costs['n_tip_events'] > 0:\n                tip_entropies.append(costs['tip_entropy_avg'])\n            if costs['n_recover_events'] > 0:\n                recover_entropies.append(costs['recover_entropy_avg'])\n    \n    # Compute statistics\n    tip_mean = np.mean(tip_entropies) if tip_entropies else 0\n    tip_std = np.std(tip_entropies) if len(tip_entropies) > 1 else 0\n    recover_mean = np.mean(recover_entropies) if recover_entropies else 0\n    recover_std = np.std(recover_entropies) if len(recover_entropies) > 1 else 0\n    \n    # Asymmetry ratio (tip/recovery)\n    if recover_mean > 0:\n        ratio = tip_mean / recover_mean\n    else:\n        ratio = np.inf if tip_mean > 0 else 1.0\n    \n    entropy_asymmetry_results[label] = {\n        'tip_entropy_mean': tip_mean,\n        'tip_entropy_std': tip_std,\n        'recover_entropy_mean': recover_mean,\n        'recover_entropy_std': recover_std,\n        'ratio': ratio,\n        'alpha': cfg['alpha']\n    }\n    \n    print(f\"\\n{label}:\")\n    print(f\"  Tip entropy:     {tip_mean:.4f} ± {tip_std:.4f}\")\n    print(f\"  Recovery entropy: {recover_mean:.4f} ± {recover_std:.4f}\")\n    print(f\"  Tip/Recovery ratio: {ratio:.2f}x\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "89grvb2ay7r",
   "source": "# Visualize entropy asymmetry across noise types\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\nlabels = list(entropy_asymmetry_results.keys())\nalphas = [entropy_asymmetry_results[l]['alpha'] for l in labels]\ncolors = [spatial_noise_results[l]['config']['color'] for l in labels]\n\n# 1. Tip vs Recovery entropy (grouped bars)\nax1 = axes[0]\nx = np.arange(len(labels))\nwidth = 0.35\n\ntip_means = [entropy_asymmetry_results[l]['tip_entropy_mean'] for l in labels]\ntip_stds = [entropy_asymmetry_results[l]['tip_entropy_std'] for l in labels]\nrecover_means = [entropy_asymmetry_results[l]['recover_entropy_mean'] for l in labels]\nrecover_stds = [entropy_asymmetry_results[l]['recover_entropy_std'] for l in labels]\n\nbars1 = ax1.bar(x - width/2, tip_means, width, yerr=tip_stds, \n                label='Tipping', color='red', alpha=0.7, capsize=3)\nbars2 = ax1.bar(x + width/2, recover_means, width, yerr=recover_stds,\n                label='Recovery', color='green', alpha=0.7, capsize=3)\n\nax1.set_xticks(x)\nax1.set_xticklabels([l.split()[0] + '\\n' + ' '.join(l.split()[1:]) for l in labels], fontsize=9)\nax1.set_ylabel('Entropy per Event')\nax1.set_title('Tip vs Recovery Entropy Cost')\nax1.legend()\nax1.grid(True, alpha=0.3, axis='y')\n\n# 2. Tip/Recovery ratio vs alpha\nax2 = axes[1]\nratios = [entropy_asymmetry_results[l]['ratio'] for l in labels]\nax2.scatter(alphas, ratios, c=colors, s=150, edgecolor='black', linewidth=1.5)\nfor i, label in enumerate(labels):\n    ax2.annotate(label.split()[0], (alphas[i], ratios[i]), \n                 xytext=(5, 5), textcoords='offset points', fontsize=9)\nax2.axhline(y=1, color='gray', linestyle='--', label='Symmetric')\nax2.set_xlabel('Lévy α (2.0 = Gaussian)')\nax2.set_ylabel('Tip/Recovery Entropy Ratio')\nax2.set_title('Entropy Asymmetry vs Noise Type')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\n# 3. Summary bar chart of ratios\nax3 = axes[2]\nbars = ax3.bar(range(len(labels)), ratios, color=colors, alpha=0.7, edgecolor='black')\nax3.axhline(y=1, color='gray', linestyle='--', linewidth=2, label='Symmetric (ratio=1)')\nax3.set_xticks(range(len(labels)))\nax3.set_xticklabels([l.replace(' ', '\\n') for l in labels], fontsize=9)\nax3.set_ylabel('Tip/Recovery Ratio')\nax3.set_title('Entropy Asymmetry by Noise Type')\nax3.legend()\nax3.grid(True, alpha=0.3, axis='y')\n\n# Add ratio values on bars\nfor i, (bar, ratio) in enumerate(zip(bars, ratios)):\n    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05,\n             f'{ratio:.2f}x', ha='center', va='bottom', fontsize=10, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\n# Interpretation\nprint(\"\\nInterpretation:\")\nprint(\"-\" * 60)\nif max(ratios) > 1.5:\n    print(\"✓ Tip/Recovery asymmetry CONFIRMED in spatial model\")\n    print(f\"  Maximum asymmetry: {max(ratios):.1f}x at α={alphas[ratios.index(max(ratios))]:.1f}\")\nelse:\n    print(\"○ Tip/Recovery asymmetry is weak in this spatial configuration\")\n    \nif ratios[0] != ratios[-1]:  # Compare Gaussian to heaviest Lévy\n    direction = \"increases\" if ratios[-1] > ratios[0] else \"decreases\"\n    print(f\"✓ Asymmetry {direction} with heavier Lévy tails (lower α)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e4x1nrkw6v",
   "source": "### Section 8 Findings: Lévy vs Gaussian Noise in Spatial Amazon Model\n\n**Hypotheses Tested:**\n\n| Hypothesis | Result | Evidence |\n|------------|--------|----------|\n| **H1**: Lévy noise enables faster cascade propagation | *See cascade propagation plot* | Compare % tipped curves across noise types |\n| **H2**: Gaussian noise produces more localized cascades | *See spatial pattern plots* | Compare spatial distributions of tipping |\n| **H3**: Tip/recovery entropy asymmetry persists in spatial networks | *See entropy analysis* | Tip/Recovery ratios by noise type |\n\n**Key Observations:**\n\n1. **Cascade Dynamics**: Different noise types produce distinct cascade propagation patterns\n   - Lévy noise (especially α < 1.5) can trigger rapid, \"jump-driven\" cascades\n   - Gaussian noise produces smoother, more gradual cascade propagation\n\n2. **Spatial Patterns**: The spatial coupling from moisture recycling interacts with noise type\n   - Heavy-tailed noise may enable \"leapfrog\" tipping across poorly-connected regions\n   - Gaussian noise respects the network topology more closely\n\n3. **Thermodynamic Costs**: The entropy asymmetry between tipping and recovery varies with noise type\n   - This validates the Phase 3 \"noise-type bifurcation\" finding in a realistic spatial context\n\n**Implications for Amazon Tipping:**\n\n- If extreme weather events (drought, fires) produce Lévy-like forcing, cascades may propagate faster than expected from network topology alone\n- Conservation strategies should consider that standard Gaussian-noise models may underestimate cascade risk\n- The \"thermodynamically favorable\" direction (tip vs recovery) depends on the noise regime",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "3ygfqo8mvpw",
   "source": "## 9. Full Network Experiment: All 567 Cells\n\nThe 50-cell subnetwork selected the **highest-connectivity cells**, which may have introduced bias toward stronger coupling and thermodynamic buffering. \n\nThis section runs the Lévy vs Gaussian comparison on the **complete 567-cell Amazon moisture recycling network** to test whether:\n1. The near-symmetric tip/recovery entropy holds at full scale\n2. Peripheral, weakly-connected regions show different behavior\n3. The \"thermodynamic buffering\" effect is a property of the full network or an artifact of cell selection\n\n### Computational Approach\n- Use Dask distributed computing for parallel ensemble runs\n- 4 noise configurations × 5 ensemble runs = 20 total simulations\n- Full 567×567 coupling matrix",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "553eie3p636",
   "source": "# Create full 567-cell Amazon network\ndef create_full_amazon_network(network, lat, lon, rain, evap, min_flow=1.0):\n    \"\"\"\n    Create energy-constrained network from ALL Amazon cells.\n    \n    Parameters\n    ----------\n    network : ndarray\n        Full moisture recycling matrix (567x567)\n    lat, lon : ndarray\n        Coordinates\n    rain, evap : ndarray\n        Rainfall and evapotranspiration\n    min_flow : float\n        Minimum moisture flow to include coupling (mm/month)\n        Lower threshold than subnetwork to capture weak connections\n    \n    Returns\n    -------\n    EnergyConstrainedNetwork\n        Full network with energy tracking\n    \"\"\"\n    import time\n    start_time = time.time()\n    \n    # Convert MaskedArrays\n    network_arr = np.ma.filled(network, 0) if hasattr(network, 'mask') else np.asarray(network)\n    lat_arr = np.ma.filled(lat, np.nan) if hasattr(lat, 'mask') else np.asarray(lat)\n    lon_arr = np.ma.filled(lon, np.nan) if hasattr(lon, 'mask') else np.asarray(lon)\n    rain_arr = np.ma.filled(rain, 0) if hasattr(rain, 'mask') else np.asarray(rain)\n    evap_arr = np.ma.filled(evap, 0) if hasattr(evap, 'mask') else np.asarray(evap)\n    \n    n_cells = len(lat_arr)\n    print(f\"Creating full Amazon network with {n_cells} cells...\")\n    \n    # Create network\n    net = EnergyConstrainedNetwork()\n    \n    # Add all elements\n    print(\"  Adding elements...\")\n    for i in range(n_cells):\n        ratio = rain_arr[i] / (evap_arr[i] + 1e-6)\n        barrier = 0.3 + 0.4 * min(ratio / 2.0, 1.0)\n        dissipation = 0.05 + 0.1 * (1 - min(ratio / 2.0, 1.0))\n        \n        element = EnergyConstrainedCusp(\n            a=-1, b=1, c=0,\n            E_stable=0.0,\n            E_tipped=1.0,\n            barrier_height=barrier,\n            dissipation_rate=dissipation,\n            heat_capacity=1.0\n        )\n        \n        element.lat = lat_arr[i]\n        element.lon = lon_arr[i]\n        element.rain = rain_arr[i]\n        element.evap = evap_arr[i]\n        \n        net.add_element(f'cell_{i}', element)\n    \n    # Add couplings (this is O(n²) but we filter by min_flow)\n    print(\"  Adding couplings...\")\n    n_couplings = 0\n    for i in range(n_cells):\n        for j in range(n_cells):\n            if i != j and network_arr[i, j] > min_flow:\n                strength = network_arr[i, j] / 100.0\n                coupling = GradientDrivenCoupling(conductivity=strength)\n                net.add_coupling(f'cell_{j}', f'cell_{i}', coupling)\n                n_couplings += 1\n        \n        # Progress indicator\n        if (i + 1) % 100 == 0:\n            print(f\"    Processed {i+1}/{n_cells} cells...\")\n    \n    elapsed = time.time() - start_time\n    density = n_couplings / (n_cells * (n_cells - 1))\n    \n    print(f\"\\nFull network created in {elapsed:.1f}s:\")\n    print(f\"  Cells: {n_cells}\")\n    print(f\"  Couplings: {n_couplings}\")\n    print(f\"  Density: {density:.4f}\")\n    \n    return net\n\n# Create the full network\nfull_amazon_net = create_full_amazon_network(\n    network, lat, lon, rain, evap, min_flow=1.0\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "gkr4nrbmdx",
   "source": "# Initialize Dask client for parallel computation\nfrom energy_constrained.dask_utils import get_dask_client, run_ensemble_parallel\n\n# Connect to Dask cluster\nclient = get_dask_client()\nprint(f\"\\nDask dashboard: {client.dashboard_link}\")\n\n# Verify workers\nn_workers = len(client.scheduler_info()['workers'])\nprint(f\"Connected to {n_workers} Dask workers\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "hppmgm9ec2o",
   "source": "# Run full network Lévy vs Gaussian comparison with Dask parallelization\nimport time\nfrom energy_constrained.dask_utils import results_to_solver_results\n\n# Same noise configurations as 50-cell experiment\nfull_noise_configs = [\n    {'label': 'Gaussian (α=2.0)', 'sigma': 0.06, 'alpha': 2.0, 'color': 'blue'},\n    {'label': 'Lévy α=1.8', 'sigma': 0.06, 'alpha': 1.8, 'color': 'orange'},\n    {'label': 'Lévy α=1.5', 'sigma': 0.06, 'alpha': 1.5, 'color': 'red'},\n    {'label': 'Lévy α=1.2 (heavy tail)', 'sigma': 0.06, 'alpha': 1.2, 'color': 'darkred'},\n]\n\n# Simulation parameters\nduration_full = 500.0\ndt_full = 0.5\nn_runs_full = 5  # Standard ensemble size\n\nprint(\"Full 567-Cell Network: Lévy vs Gaussian Comparison\")\nprint(\"=\" * 70)\nprint(f\"Network size: {full_amazon_net.n_elements} cells\")\nprint(f\"Duration: {duration_full} time units\")\nprint(f\"Ensemble size: {n_runs_full} runs per configuration\")\nprint(f\"Total simulations: {len(full_noise_configs) * n_runs_full}\")\nprint(f\"\\nUsing Dask parallelization across {n_workers} workers\")\n\nfull_network_results = {}\ntotal_start = time.time()\n\nfor cfg in full_noise_configs:\n    label = cfg['label']\n    print(f\"\\n{'='*70}\")\n    print(f\"Running: {label} on full {full_amazon_net.n_elements}-cell network\")\n    print('='*70)\n    \n    cfg_start = time.time()\n    \n    # Run parallel ensemble using Dask\n    results_dict = run_ensemble_parallel(\n        full_amazon_net,\n        n_runs=n_runs_full,\n        duration=duration_full,\n        dt=dt_full,\n        sigma=cfg['sigma'],\n        alpha=cfg['alpha'],\n        seed=42,\n        client=client,\n        batch_size=n_workers  # One simulation per worker\n    )\n    \n    # Convert dict results to SolverResult objects for analysis\n    results = results_to_solver_results(results_dict)\n    \n    cfg_elapsed = time.time() - cfg_start\n    \n    # Analyze thermodynamics\n    thermo = analyze_ensemble_thermodynamics(full_amazon_net, results)\n    \n    full_network_results[label] = {\n        'config': cfg,\n        'results': results,\n        'thermo': thermo,\n        'runtime': cfg_elapsed\n    }\n    \n    print(f\"\\nResults for {label} (completed in {cfg_elapsed:.1f}s):\")\n    print(f\"  Total entropy: {thermo['total_entropy']['mean']:.1f} ± {thermo['total_entropy']['std']:.1f}\")\n    print(f\"  Tipping events: {thermo['n_tip_events']['mean']:.1f} ± {thermo['n_tip_events']['std']:.1f}\")\n    print(f\"  Mean time tipped: {100*np.mean(thermo['element_time_tipped']['mean']):.1f}%\")\n\ntotal_elapsed = time.time() - total_start\nprint(\"\\n\" + \"=\"*70)\nprint(f\"Full network experiment complete!\")\nprint(f\"Total runtime: {total_elapsed/60:.1f} minutes\")\nprint(\"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ndmxrnzjumg",
   "source": "# Visualize full network cascade propagation\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# 1. Cascade propagation (% tipped over time)\nax1 = axes[0, 0]\nfor label, data in full_network_results.items():\n    cfg = data['config']\n    results = data['results']\n    \n    frac_tipped_all = []\n    for r in results:\n        frac_tipped = np.mean(r.x > 0, axis=1) * 100\n        frac_tipped_all.append(frac_tipped)\n    \n    mean_tipped = np.mean(frac_tipped_all, axis=0)\n    std_tipped = np.std(frac_tipped_all, axis=0)\n    t = results[0].t\n    \n    ax1.plot(t, mean_tipped, color=cfg['color'], linewidth=2, label=label)\n    ax1.fill_between(t, mean_tipped - std_tipped, mean_tipped + std_tipped, \n                     color=cfg['color'], alpha=0.2)\n\nax1.set_xlabel('Time')\nax1.set_ylabel('% Cells Tipped')\nax1.set_title(f'Cascade Propagation: Full {full_amazon_net.n_elements}-Cell Network')\nax1.legend(loc='lower right')\nax1.grid(True, alpha=0.3)\n\n# 2. Total entropy production\nax2 = axes[0, 1]\nlabels = list(full_network_results.keys())\ncolors = [full_network_results[l]['config']['color'] for l in labels]\nentropy_means = [full_network_results[l]['thermo']['total_entropy']['mean'] for l in labels]\nentropy_stds = [full_network_results[l]['thermo']['total_entropy']['std'] for l in labels]\n\nbars = ax2.bar(range(len(labels)), entropy_means, yerr=entropy_stds, \n               color=colors, alpha=0.7, capsize=5)\nax2.set_xticks(range(len(labels)))\nax2.set_xticklabels([l.replace(' ', '\\n') for l in labels], fontsize=9)\nax2.set_ylabel('Total Entropy Produced')\nax2.set_title('Entropy Production (Full Network)')\nax2.grid(True, alpha=0.3, axis='y')\n\n# 3. Number of tipping events\nax3 = axes[1, 0]\ntip_means = [full_network_results[l]['thermo']['n_tip_events']['mean'] for l in labels]\ntip_stds = [full_network_results[l]['thermo']['n_tip_events']['std'] for l in labels]\n\nbars = ax3.bar(range(len(labels)), tip_means, yerr=tip_stds,\n               color=colors, alpha=0.7, capsize=5)\nax3.set_xticks(range(len(labels)))\nax3.set_xticklabels([l.replace(' ', '\\n') for l in labels], fontsize=9)\nax3.set_ylabel('Number of Tipping Events')\nax3.set_title('Tipping Event Frequency (Full Network)')\nax3.grid(True, alpha=0.3, axis='y')\n\n# 4. Runtime comparison\nax4 = axes[1, 1]\nruntimes = [full_network_results[l]['runtime'] for l in labels]\nbars = ax4.bar(range(len(labels)), runtimes, color=colors, alpha=0.7)\nax4.set_xticks(range(len(labels)))\nax4.set_xticklabels([l.replace(' ', '\\n') for l in labels], fontsize=9)\nax4.set_ylabel('Runtime (seconds)')\nax4.set_title('Computation Time per Configuration')\nax4.grid(True, alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.suptitle(f'Full Amazon Network ({full_amazon_net.n_elements} cells): Lévy vs Gaussian', \n             fontsize=14, y=1.02)\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "v0pe554eeu8",
   "source": "# Spatial patterns for full network\nfig, axes = plt.subplots(2, 2, figsize=(16, 14))\n\nfor ax, (label, data) in zip(axes.flat, full_network_results.items()):\n    cfg = data['config']\n    results = data['results']\n    \n    # Mean time tipped per cell across ensemble\n    time_tipped_all = []\n    for r in results:\n        time_tipped = np.mean(r.x > 0, axis=0) * 100\n        time_tipped_all.append(time_tipped)\n    \n    mean_time_tipped = np.mean(time_tipped_all, axis=0)\n    \n    # Plot ALL cells colored by time tipped\n    sc = ax.scatter(lon, lat, c=mean_time_tipped, cmap='RdYlGn_r', \n                    s=15, edgecolor='none', vmin=0, vmax=100, alpha=0.8)\n    \n    ax.set_xlabel('Longitude')\n    ax.set_ylabel('Latitude')\n    ax.set_title(f'{label}\\nMean: {np.mean(mean_time_tipped):.1f}% tipped')\n    plt.colorbar(sc, ax=ax, label='% Time Tipped')\n\nplt.suptitle('Spatial Tipping Patterns: Full Amazon Network', fontsize=14, y=1.02)\nplt.tight_layout()\nplt.show()\n\nprint(\"Key observation: Compare which regions tip under different noise regimes\")\nprint(\"- Red regions: Frequently tipped (vulnerable)\")\nprint(\"- Green regions: Rarely tipped (resilient)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "zk962znicw",
   "source": "# Tip/Recovery entropy asymmetry for full network\nprint(\"Full Network: Tip vs Recovery Entropy Analysis\")\nprint(\"=\" * 70)\n\nfull_entropy_asymmetry = {}\n\nfor label, data in full_network_results.items():\n    cfg = data['config']\n    results = data['results']\n    \n    tip_entropies = []\n    recover_entropies = []\n    \n    for result in results:\n        analyzer = EnergyAnalyzer(full_amazon_net, result)\n        events = analyzer.identify_tipping_events()\n        \n        if events:\n            costs = analyzer.compute_cascade_energy_costs(events)\n            \n            if costs['n_tip_events'] > 0:\n                tip_entropies.append(costs['tip_entropy_avg'])\n            if costs['n_recover_events'] > 0:\n                recover_entropies.append(costs['recover_entropy_avg'])\n    \n    tip_mean = np.mean(tip_entropies) if tip_entropies else 0\n    tip_std = np.std(tip_entropies) if len(tip_entropies) > 1 else 0\n    recover_mean = np.mean(recover_entropies) if recover_entropies else 0\n    recover_std = np.std(recover_entropies) if len(recover_entropies) > 1 else 0\n    \n    ratio = tip_mean / recover_mean if recover_mean > 0 else (np.inf if tip_mean > 0 else 1.0)\n    \n    full_entropy_asymmetry[label] = {\n        'tip_entropy_mean': tip_mean,\n        'tip_entropy_std': tip_std,\n        'recover_entropy_mean': recover_mean,\n        'recover_entropy_std': recover_std,\n        'ratio': ratio,\n        'alpha': cfg['alpha']\n    }\n    \n    print(f\"\\n{label}:\")\n    print(f\"  Tip entropy:      {tip_mean:.2f} ± {tip_std:.2f}\")\n    print(f\"  Recovery entropy: {recover_mean:.2f} ± {recover_std:.2f}\")\n    print(f\"  Tip/Recovery ratio: {ratio:.3f}x\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "gje2gknsp3p",
   "source": "# Compare 50-cell vs full network entropy asymmetry\nfig, axes = plt.subplots(1, 3, figsize=(16, 5))\n\nlabels = list(full_entropy_asymmetry.keys())\nalphas = [full_entropy_asymmetry[l]['alpha'] for l in labels]\ncolors = [full_network_results[l]['config']['color'] for l in labels]\n\n# 1. Tip vs Recovery entropy (full network)\nax1 = axes[0]\nx = np.arange(len(labels))\nwidth = 0.35\n\ntip_means = [full_entropy_asymmetry[l]['tip_entropy_mean'] for l in labels]\ntip_stds = [full_entropy_asymmetry[l]['tip_entropy_std'] for l in labels]\nrecover_means = [full_entropy_asymmetry[l]['recover_entropy_mean'] for l in labels]\nrecover_stds = [full_entropy_asymmetry[l]['recover_entropy_std'] for l in labels]\n\nbars1 = ax1.bar(x - width/2, tip_means, width, yerr=tip_stds, \n                label='Tipping', color='red', alpha=0.7, capsize=3)\nbars2 = ax1.bar(x + width/2, recover_means, width, yerr=recover_stds,\n                label='Recovery', color='green', alpha=0.7, capsize=3)\n\nax1.set_xticks(x)\nax1.set_xticklabels([l.split()[0] + '\\n' + ' '.join(l.split()[1:]) for l in labels], fontsize=9)\nax1.set_ylabel('Entropy per Event')\nax1.set_title('Full Network: Tip vs Recovery Entropy')\nax1.legend()\nax1.grid(True, alpha=0.3, axis='y')\n\n# 2. Compare ratios: 50-cell vs full network\nax2 = axes[1]\nratios_50 = [entropy_asymmetry_results[l]['ratio'] for l in labels]\nratios_full = [full_entropy_asymmetry[l]['ratio'] for l in labels]\n\nx = np.arange(len(labels))\nwidth = 0.35\nbars1 = ax2.bar(x - width/2, ratios_50, width, label='50-cell subnet', color='lightblue', edgecolor='blue')\nbars2 = ax2.bar(x + width/2, ratios_full, width, label='567-cell full', color='lightcoral', edgecolor='red')\n\nax2.axhline(y=1, color='gray', linestyle='--', linewidth=2, label='Symmetric')\nax2.set_xticks(x)\nax2.set_xticklabels([l.split()[0] for l in labels], fontsize=10)\nax2.set_ylabel('Tip/Recovery Ratio')\nax2.set_title('Entropy Asymmetry: Subnetwork vs Full Network')\nax2.legend()\nax2.grid(True, alpha=0.3, axis='y')\n\n# 3. Ratio vs alpha for both network sizes\nax3 = axes[2]\nax3.scatter(alphas, ratios_50, c='blue', s=120, marker='o', label='50-cell subnet', edgecolor='black')\nax3.scatter(alphas, ratios_full, c='red', s=120, marker='s', label='567-cell full', edgecolor='black')\nax3.axhline(y=1, color='gray', linestyle='--', label='Symmetric')\nax3.set_xlabel('Lévy α (2.0 = Gaussian)')\nax3.set_ylabel('Tip/Recovery Entropy Ratio')\nax3.set_title('Asymmetry vs Noise Type')\nax3.legend()\nax3.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Summary comparison\nprint(\"\\nComparison: 50-cell Subnetwork vs Full 567-cell Network\")\nprint(\"=\" * 70)\nprint(f\"{'Noise Type':<25} {'50-cell Ratio':>15} {'Full Ratio':>15} {'Difference':>15}\")\nprint(\"-\" * 70)\nfor label in labels:\n    r50 = entropy_asymmetry_results[label]['ratio']\n    rfull = full_entropy_asymmetry[label]['ratio']\n    diff = rfull - r50\n    print(f\"{label:<25} {r50:>15.4f} {rfull:>15.4f} {diff:>+15.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5a0kvi3to4o",
   "source": "### Section 9 Findings: Full Network vs Subnetwork\n\n**Key Questions Addressed:**\n\n| Question | Finding |\n|----------|---------|\n| Does near-symmetric entropy hold at full scale? | *Compare ratios above* |\n| Do peripheral regions behave differently? | *See spatial pattern maps* |\n| Is thermodynamic buffering a network property? | *Compare 50-cell vs 567-cell results* |\n\n**Scaling Effects:**\n\nThe full 567-cell network includes:\n- **Peripheral cells** with weak moisture recycling connections\n- **Interior cells** with strong bidirectional coupling\n- **Coastal cells** that are primarily moisture sources (high out-degree)\n\n**Comparison Summary:**\n\n1. **Entropy Production**: The full network produces [more/less/similar] total entropy than the high-connectivity subnetwork\n\n2. **Asymmetry Patterns**: The tip/recovery ratio in the full network is [more/less/equally] symmetric compared to the 50-cell subset\n\n3. **Spatial Heterogeneity**: The full network reveals [which regions] are most vulnerable under different noise regimes\n\n**Implications:**\n\n- If the full network shows stronger asymmetry → peripheral cells may act as \"tipping amplifiers\"\n- If asymmetry remains weak → the moisture recycling network provides robust thermodynamic buffering at all scales\n- The comparison informs whether conservation efforts should focus on high-connectivity hubs vs. network-wide protection",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "qlb1oeiwynr",
   "source": "## 10. Drought Scenario Analysis\n\nThe Amazon experienced major droughts in **2005** and **2010** (data not available for 2015). This section tests how drought conditions affect cascade thermodynamics compared to normal years.\n\n### Historical Drought Events\n- **2005 drought**: Record drought, widespread forest fires, -7.5% rainfall anomaly\n- **2010 drought**: Even more severe than 2005, -10.2% rainfall anomaly (Lewis et al., 2011)\n\n### Approach\n1. Load moisture recycling data for drought months vs normal months\n2. Compare network coupling strength during droughts\n3. Simulate cascades under drought vs normal conditions\n4. Analyze thermodynamic costs of drought-induced tipping\n\n### Key Hypothesis\nDroughts weaken moisture recycling → reduced coupling → lower barriers → increased cascade vulnerability",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "d6fbvjidpq",
   "source": "# Load drought vs normal year data\ndef load_year_data(year, months=None):\n    \"\"\"\n    Load and average moisture recycling data for a given year.\n    \n    Parameters\n    ----------\n    year : int\n        Year to load (2003-2014)\n    months : list, optional\n        Specific months to average (1-12). Default: all months\n    \n    Returns\n    -------\n    dict : Contains lat, lon, rain, evap, network averaged over months\n    \"\"\"\n    if months is None:\n        months = list(range(1, 13))\n    \n    rain_all = []\n    evap_all = []\n    network_all = []\n    lat = None\n    lon = None\n    \n    for month in months:\n        filepath = data_root / 'average_network' / 'era5_new_network_data' / f'1deg_{year}_{month:02d}.nc'\n        \n        if not filepath.exists():\n            print(f\"  Warning: {filepath.name} not found, skipping\")\n            continue\n        \n        if NETCDF_AVAILABLE:\n            ds = Dataset(filepath)\n            if lat is None:\n                lat = np.ma.filled(ds.variables['lat'][:], np.nan)\n                lon = np.ma.filled(ds.variables['lon'][:], np.nan)\n            rain_all.append(np.ma.filled(ds.variables['rain'][:], 0))\n            evap_all.append(np.ma.filled(ds.variables['evap'][:], 0))\n            network_all.append(np.ma.filled(ds.variables['network'][:], 0))\n            ds.close()\n        else:\n            ds = xr.open_dataset(filepath)\n            if lat is None:\n                lat = ds['lat'].values\n                lon = ds['lon'].values\n            rain_all.append(ds['rain'].values)\n            evap_all.append(ds['evap'].values)\n            network_all.append(ds['network'].values)\n            ds.close()\n    \n    return {\n        'year': year,\n        'months': months,\n        'lat': lat,\n        'lon': lon,\n        'rain': np.mean(rain_all, axis=0),\n        'evap': np.mean(evap_all, axis=0),\n        'network': np.mean(network_all, axis=0)\n    }\n\n# Load normal year (2003) and drought years (2005, 2010)\nprint(\"Loading multi-year moisture recycling data...\")\nprint(\"=\" * 60)\n\n# Use dry season months (July-September) when droughts are most severe\ndry_season_months = [7, 8, 9]\n\nprint(f\"\\nLoading 2003 (normal year, months {dry_season_months})...\")\ndata_2003 = load_year_data(2003, months=dry_season_months)\n\nprint(f\"Loading 2005 (drought year, months {dry_season_months})...\")\ndata_2005 = load_year_data(2005, months=dry_season_months)\n\nprint(f\"Loading 2010 (severe drought, months {dry_season_months})...\")\ndata_2010 = load_year_data(2010, months=dry_season_months)\n\nprint(\"\\nData loaded successfully!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "78zvgsfe6j8",
   "source": "# Compare rainfall and moisture recycling between normal and drought years\nfig, axes = plt.subplots(2, 3, figsize=(16, 10))\n\nyears_data = [data_2003, data_2005, data_2010]\nyear_labels = ['2003 (Normal)', '2005 (Drought)', '2010 (Severe Drought)']\nyear_colors = ['blue', 'orange', 'red']\n\n# Row 1: Rainfall maps\nfor i, (data, label) in enumerate(zip(years_data, year_labels)):\n    ax = axes[0, i]\n    sc = ax.scatter(data['lon'], data['lat'], c=data['rain'], cmap='Blues', \n                    s=10, vmin=0, vmax=250)\n    ax.set_title(f'{label}\\nRainfall')\n    ax.set_xlabel('Longitude')\n    ax.set_ylabel('Latitude')\n    plt.colorbar(sc, ax=ax, label='mm/month')\n\n# Row 2: Network strength (total coupling per cell)\nfor i, (data, label) in enumerate(zip(years_data, year_labels)):\n    ax = axes[1, i]\n    total_coupling = np.sum(data['network'], axis=0) + np.sum(data['network'], axis=1)\n    sc = ax.scatter(data['lon'], data['lat'], c=total_coupling, cmap='YlOrRd', \n                    s=10, vmin=0)\n    ax.set_title(f'{label}\\nMoisture Recycling Strength')\n    ax.set_xlabel('Longitude')\n    ax.set_ylabel('Latitude')\n    plt.colorbar(sc, ax=ax, label='Total flow (mm)')\n\nplt.tight_layout()\nplt.show()\n\n# Quantitative comparison\nprint(\"\\nDrought Impact on Moisture Recycling\")\nprint(\"=\" * 60)\nprint(f\"{'Metric':<30} {'2003':>10} {'2005':>10} {'2010':>10}\")\nprint(\"-\" * 60)\n\nfor metric, key in [('Mean rainfall (mm/mo)', 'rain'), \n                     ('Mean evap (mm/mo)', 'evap')]:\n    vals = [np.mean(d[key]) for d in years_data]\n    print(f\"{metric:<30} {vals[0]:>10.1f} {vals[1]:>10.1f} {vals[2]:>10.1f}\")\n\n# Network metrics\ntotal_flows = [np.sum(d['network']) for d in years_data]\nprint(f\"{'Total network flow (mm)':.<30} {total_flows[0]:>10.0f} {total_flows[1]:>10.0f} {total_flows[2]:>10.0f}\")\n\n# Relative to 2003\nprint(\"\\n% Change relative to 2003:\")\nprint(f\"  2005 rainfall: {100*(np.mean(data_2005['rain'])/np.mean(data_2003['rain'])-1):+.1f}%\")\nprint(f\"  2005 network:  {100*(np.sum(data_2005['network'])/np.sum(data_2003['network'])-1):+.1f}%\")\nprint(f\"  2010 rainfall: {100*(np.mean(data_2010['rain'])/np.mean(data_2003['rain'])-1):+.1f}%\")\nprint(f\"  2010 network:  {100*(np.sum(data_2010['network'])/np.sum(data_2003['network'])-1):+.1f}%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6scpq18dq3l",
   "source": "# Create networks for each year condition\ndef create_network_from_data(data, n_cells=50, min_flow=5.0):\n    \"\"\"\n    Create an energy-constrained network from year-specific data.\n    \n    Uses year-specific rainfall/evap to set barrier heights,\n    and year-specific moisture recycling for coupling strengths.\n    \"\"\"\n    network_arr = data['network']\n    lat_arr = data['lat']\n    lon_arr = data['lon']\n    rain_arr = data['rain']\n    evap_arr = data['evap']\n    \n    # Select top-connected cells (same indices for comparability)\n    total_flow = np.sum(network_arr, axis=0) + np.sum(network_arr, axis=1)\n    top_indices = np.argsort(total_flow)[-n_cells:]\n    \n    # Create subnetwork\n    sub_network = network_arr[np.ix_(top_indices, top_indices)]\n    sub_lat = lat_arr[top_indices]\n    sub_lon = lon_arr[top_indices]\n    sub_rain = rain_arr[top_indices]\n    sub_evap = evap_arr[top_indices]\n    \n    # Create energy-constrained network\n    net = EnergyConstrainedNetwork()\n    \n    for i in range(n_cells):\n        ratio = sub_rain[i] / (sub_evap[i] + 1e-6)\n        # Lower ratio during drought = lower barrier (more vulnerable)\n        barrier = 0.3 + 0.4 * min(ratio / 2.0, 1.0)\n        dissipation = 0.05 + 0.1 * (1 - min(ratio / 2.0, 1.0))\n        \n        element = EnergyConstrainedCusp(\n            a=-1, b=1, c=0,\n            E_stable=0.0,\n            E_tipped=1.0,\n            barrier_height=barrier,\n            dissipation_rate=dissipation,\n            heat_capacity=1.0\n        )\n        \n        element.lat = sub_lat[i]\n        element.lon = sub_lon[i]\n        element.rain = sub_rain[i]\n        element.evap = sub_evap[i]\n        \n        net.add_element(f'cell_{i}', element)\n    \n    # Add couplings (weaker during drought)\n    n_couplings = 0\n    for i in range(n_cells):\n        for j in range(n_cells):\n            if i != j and sub_network[i, j] > min_flow:\n                strength = sub_network[i, j] / 100.0\n                coupling = GradientDrivenCoupling(conductivity=strength)\n                net.add_coupling(f'cell_{j}', f'cell_{i}', coupling)\n                n_couplings += 1\n    \n    return net, top_indices\n\n# Create networks for each year\nprint(\"Creating energy-constrained networks...\")\nprint(\"=\" * 60)\n\nnet_2003, indices_2003 = create_network_from_data(data_2003, n_cells=50)\nprint(f\"2003 (Normal): {net_2003.n_elements} cells, {len(list(net_2003.edges()))} couplings\")\n\nnet_2005, indices_2005 = create_network_from_data(data_2005, n_cells=50)\nprint(f\"2005 (Drought): {net_2005.n_elements} cells, {len(list(net_2005.edges()))} couplings\")\n\nnet_2010, indices_2010 = create_network_from_data(data_2010, n_cells=50)\nprint(f\"2010 (Severe): {net_2010.n_elements} cells, {len(list(net_2010.edges()))} couplings\")\n\n# Compare barrier heights\nbarriers_2003 = [net_2003.get_element(f'cell_{i}').barrier_height for i in range(50)]\nbarriers_2005 = [net_2005.get_element(f'cell_{i}').barrier_height for i in range(50)]\nbarriers_2010 = [net_2010.get_element(f'cell_{i}').barrier_height for i in range(50)]\n\nprint(f\"\\nMean barrier heights:\")\nprint(f\"  2003: {np.mean(barriers_2003):.3f}\")\nprint(f\"  2005: {np.mean(barriers_2005):.3f} ({100*(np.mean(barriers_2005)/np.mean(barriers_2003)-1):+.1f}%)\")\nprint(f\"  2010: {np.mean(barriers_2010):.3f} ({100*(np.mean(barriers_2010)/np.mean(barriers_2003)-1):+.1f}%)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "pcn46yx6a",
   "source": "# Run cascade simulations under drought vs normal conditions\nfrom energy_constrained.solvers import run_ensemble\n\n# Simulation parameters\nduration_drought = 500.0\ndt_drought = 0.5\nn_runs_drought = 5\nsigma_drought = 0.06  # Same noise level for fair comparison\nalpha_drought = 2.0   # Gaussian noise\n\nprint(\"Running cascade simulations under different climate conditions...\")\nprint(\"=\" * 70)\nprint(f\"Simulation: duration={duration_drought}, dt={dt_drought}, n_runs={n_runs_drought}\")\nprint(f\"Noise: sigma={sigma_drought}, alpha={alpha_drought} (Gaussian)\")\n\ndrought_results = {}\n\nfor label, net in [('2003 (Normal)', net_2003), \n                   ('2005 (Drought)', net_2005), \n                   ('2010 (Severe)', net_2010)]:\n    print(f\"\\n{'='*60}\")\n    print(f\"Running: {label}\")\n    print('='*60)\n    \n    results = run_ensemble(\n        net,\n        n_runs=n_runs_drought,\n        duration=duration_drought,\n        dt=dt_drought,\n        sigma=sigma_drought,\n        alpha=alpha_drought,\n        seed=42,\n        progress=True\n    )\n    \n    # Analyze\n    thermo = analyze_ensemble_thermodynamics(net, results)\n    \n    drought_results[label] = {\n        'network': net,\n        'results': results,\n        'thermo': thermo\n    }\n    \n    print(f\"\\n{label} results:\")\n    print(f\"  Total entropy: {thermo['total_entropy']['mean']:.1f} ± {thermo['total_entropy']['std']:.1f}\")\n    print(f\"  Tipping events: {thermo['n_tip_events']['mean']:.1f} ± {thermo['n_tip_events']['std']:.1f}\")\n    print(f\"  Mean time tipped: {100*np.mean(thermo['element_time_tipped']['mean']):.1f}%\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"All drought simulations complete!\")\nprint(\"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "xz5o5p8dogs",
   "source": "# Visualize drought impact on cascade dynamics\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\nlabels = list(drought_results.keys())\ncolors = ['blue', 'orange', 'red']\n\n# 1. Cascade propagation over time\nax1 = axes[0, 0]\nfor (label, data), color in zip(drought_results.items(), colors):\n    results = data['results']\n    \n    frac_tipped_all = []\n    for r in results:\n        frac_tipped = np.mean(r.x > 0, axis=1) * 100\n        frac_tipped_all.append(frac_tipped)\n    \n    mean_tipped = np.mean(frac_tipped_all, axis=0)\n    std_tipped = np.std(frac_tipped_all, axis=0)\n    t = results[0].t\n    \n    ax1.plot(t, mean_tipped, color=color, linewidth=2, label=label)\n    ax1.fill_between(t, mean_tipped - std_tipped, mean_tipped + std_tipped, \n                     color=color, alpha=0.2)\n\nax1.set_xlabel('Time')\nax1.set_ylabel('% Cells Tipped')\nax1.set_title('Cascade Propagation: Drought Impact')\nax1.legend(loc='lower right')\nax1.grid(True, alpha=0.3)\n\n# 2. Total entropy production\nax2 = axes[0, 1]\nentropy_means = [drought_results[l]['thermo']['total_entropy']['mean'] for l in labels]\nentropy_stds = [drought_results[l]['thermo']['total_entropy']['std'] for l in labels]\n\nbars = ax2.bar(range(len(labels)), entropy_means, yerr=entropy_stds, \n               color=colors, alpha=0.7, capsize=5)\nax2.set_xticks(range(len(labels)))\nax2.set_xticklabels(labels, fontsize=10)\nax2.set_ylabel('Total Entropy Produced')\nax2.set_title('Entropy Production Under Drought')\nax2.grid(True, alpha=0.3, axis='y')\n\n# Add % change labels\nfor i, (bar, val) in enumerate(zip(bars, entropy_means)):\n    if i > 0:\n        pct_change = 100 * (val / entropy_means[0] - 1)\n        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + entropy_stds[i] + 2,\n                 f'{pct_change:+.0f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')\n\n# 3. Number of tipping events\nax3 = axes[1, 0]\ntip_means = [drought_results[l]['thermo']['n_tip_events']['mean'] for l in labels]\ntip_stds = [drought_results[l]['thermo']['n_tip_events']['std'] for l in labels]\n\nbars = ax3.bar(range(len(labels)), tip_means, yerr=tip_stds,\n               color=colors, alpha=0.7, capsize=5)\nax3.set_xticks(range(len(labels)))\nax3.set_xticklabels(labels, fontsize=10)\nax3.set_ylabel('Number of Tipping Events')\nax3.set_title('Tipping Event Frequency')\nax3.grid(True, alpha=0.3, axis='y')\n\n# 4. Mean time tipped per cell\nax4 = axes[1, 1]\ntime_tipped_means = [100*np.mean(drought_results[l]['thermo']['element_time_tipped']['mean']) for l in labels]\ntime_tipped_stds = [100*np.std(drought_results[l]['thermo']['element_time_tipped']['mean']) for l in labels]\n\nbars = ax4.bar(range(len(labels)), time_tipped_means, yerr=time_tipped_stds,\n               color=colors, alpha=0.7, capsize=5)\nax4.set_xticks(range(len(labels)))\nax4.set_xticklabels(labels, fontsize=10)\nax4.set_ylabel('Mean % Time Tipped')\nax4.set_title('Time Spent in Tipped State')\nax4.grid(True, alpha=0.3, axis='y')\n\nplt.suptitle('Drought Impact on Amazon Cascade Thermodynamics', fontsize=14, y=1.02)\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "vshf39pp0tp",
   "source": "# Analyze tip/recovery asymmetry under drought conditions\nprint(\"Tip vs Recovery Entropy: Drought Impact\")\nprint(\"=\" * 70)\n\ndrought_asymmetry = {}\n\nfor label, data in drought_results.items():\n    net = data['network']\n    results = data['results']\n    \n    tip_entropies = []\n    recover_entropies = []\n    \n    for result in results:\n        analyzer = EnergyAnalyzer(net, result)\n        events = analyzer.identify_tipping_events()\n        \n        if events:\n            costs = analyzer.compute_cascade_energy_costs(events)\n            \n            if costs['n_tip_events'] > 0:\n                tip_entropies.append(costs['tip_entropy_avg'])\n            if costs['n_recover_events'] > 0:\n                recover_entropies.append(costs['recover_entropy_avg'])\n    \n    tip_mean = np.mean(tip_entropies) if tip_entropies else 0\n    tip_std = np.std(tip_entropies) if len(tip_entropies) > 1 else 0\n    recover_mean = np.mean(recover_entropies) if recover_entropies else 0\n    recover_std = np.std(recover_entropies) if len(recover_entropies) > 1 else 0\n    \n    ratio = tip_mean / recover_mean if recover_mean > 0 else (np.inf if tip_mean > 0 else 1.0)\n    \n    drought_asymmetry[label] = {\n        'tip_entropy': (tip_mean, tip_std),\n        'recover_entropy': (recover_mean, recover_std),\n        'ratio': ratio\n    }\n    \n    print(f\"\\n{label}:\")\n    print(f\"  Tip entropy:      {tip_mean:.4f} ± {tip_std:.4f}\")\n    print(f\"  Recovery entropy: {recover_mean:.4f} ± {recover_std:.4f}\")\n    print(f\"  Tip/Recovery ratio: {ratio:.3f}x\")\n\n# Visualization\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# 1. Tip vs Recovery entropy by year\nax1 = axes[0]\nx = np.arange(len(labels))\nwidth = 0.35\n\ntip_vals = [drought_asymmetry[l]['tip_entropy'][0] for l in labels]\ntip_errs = [drought_asymmetry[l]['tip_entropy'][1] for l in labels]\nrec_vals = [drought_asymmetry[l]['recover_entropy'][0] for l in labels]\nrec_errs = [drought_asymmetry[l]['recover_entropy'][1] for l in labels]\n\nax1.bar(x - width/2, tip_vals, width, yerr=tip_errs, label='Tipping', color='red', alpha=0.7, capsize=3)\nax1.bar(x + width/2, rec_vals, width, yerr=rec_errs, label='Recovery', color='green', alpha=0.7, capsize=3)\nax1.set_xticks(x)\nax1.set_xticklabels(labels, fontsize=10)\nax1.set_ylabel('Entropy per Event')\nax1.set_title('Tip vs Recovery Entropy: Drought Impact')\nax1.legend()\nax1.grid(True, alpha=0.3, axis='y')\n\n# 2. Tip/Recovery ratio\nax2 = axes[1]\nratios = [drought_asymmetry[l]['ratio'] for l in labels]\nbars = ax2.bar(range(len(labels)), ratios, color=colors, alpha=0.7)\nax2.axhline(y=1, color='gray', linestyle='--', linewidth=2, label='Symmetric')\nax2.set_xticks(range(len(labels)))\nax2.set_xticklabels(labels, fontsize=10)\nax2.set_ylabel('Tip/Recovery Entropy Ratio')\nax2.set_title('Entropy Asymmetry by Climate Condition')\nax2.legend()\nax2.grid(True, alpha=0.3, axis='y')\n\n# Add ratio values\nfor bar, ratio in zip(bars, ratios):\n    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n             f'{ratio:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\n# Summary\nprint(\"\\n\" + \"=\"*70)\nprint(\"Summary: Drought Impact on Thermodynamic Asymmetry\")\nprint(\"=\"*70)\nif ratios[2] != ratios[0]:\n    if ratios[2] > ratios[0]:\n        print(f\"2010 drought INCREASES tip/recovery asymmetry by {100*(ratios[2]/ratios[0]-1):+.1f}%\")\n        print(\"  -> Tipping becomes thermodynamically MORE costly relative to recovery\")\n    else:\n        print(f\"2010 drought DECREASES tip/recovery asymmetry by {100*(ratios[2]/ratios[0]-1):+.1f}%\")\n        print(\"  -> Tipping becomes thermodynamically LESS costly relative to recovery\")\nelse:\n    print(\"No significant change in tip/recovery asymmetry under drought\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "s2dgqco09pk",
   "source": "### Section 10 Findings: Drought Impact on Cascade Thermodynamics\n\n**Hypothesis Tested**: Droughts weaken moisture recycling → reduced coupling → lower barriers → increased cascade vulnerability\n\n**Key Metrics Compared**:\n\n| Metric | 2003 (Normal) | 2005 (Drought) | 2010 (Severe) |\n|--------|---------------|----------------|---------------|\n| Mean rainfall | *See above* | *% change* | *% change* |\n| Network flow | *baseline* | *% change* | *% change* |\n| Mean barrier height | *baseline* | *% change* | *% change* |\n| Tipping events | *baseline* | *% change* | *% change* |\n| Total entropy | *baseline* | *% change* | *% change* |\n\n**Mechanistic Insights**:\n\n1. **Lower barriers during drought**: Reduced rainfall/evap ratio directly lowers thermodynamic barriers to tipping\n\n2. **Weaker coupling during drought**: Reduced moisture recycling means cells are less connected, potentially both:\n   - Reducing cascade propagation speed (fewer pathways)\n   - Reducing recovery assistance from neighbors (less buffering)\n\n3. **Thermodynamic cost shift**: Does drought make tipping \"cheaper\" or \"more expensive\" in entropy terms?\n\n**Implications for Amazon Tipping Points**:\n\n- If drought increases vulnerability but also increases the entropy cost of tipping, there may be a thermodynamic \"lag\" before irreversible cascade\n- If drought decreases the entropy cost of tipping, the system becomes more prone to sudden, \"cheap\" cascades\n- The 2005 and 2010 droughts may have brought the Amazon closer to these thermodynamic thresholds\n\n**References**:\n- Lewis, S. L., et al. (2011). The 2010 Amazon drought. *Science*, 331(6017), 554.\n- Marengo, J. A., et al. (2008). The drought of Amazonia in 2005. *Journal of Climate*, 21(3), 495-516.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}