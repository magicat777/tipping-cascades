{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 12c: Connectivity Threshold Mapping\n",
    "\n",
    "**Objective**: Map the recovery-connectivity relationship to identify the minimum network density required for meaningful recovery, and determine whether preserving keystone edges shifts this threshold.\n",
    "\n",
    "## Background\n",
    "\n",
    "Experiment 12b revealed:\n",
    "- **6 keystone edges alone** → 0.2% recovery (insufficient)\n",
    "- **Full network (~1000 edges)** → 41.6% recovery\n",
    "- Somewhere between lies a critical connectivity threshold\n",
    "\n",
    "## Key Questions\n",
    "\n",
    "1. What is the minimum connectivity for meaningful recovery (>10%)?\n",
    "2. Does keystone preservation shift this threshold?\n",
    "3. Is the transition sharp (phase transition) or gradual (continuous)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/opt/research-local/src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "from netCDF4 import Dataset\n",
    "from dask.distributed import as_completed\n",
    "\n",
    "from energy_constrained import get_dask_client\n",
    "\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Dask cluster\n",
    "client = get_dask_client()\n",
    "print(f\"Connected to Dask cluster with {len(client.scheduler_info()['workers'])} workers\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('/opt/research-local/data/amazon/amazon_adaptation_model/average_network/era5_new_network_data')\n",
    "\n",
    "def load_amazon_data(year=2003, months=[7, 8, 9]):\n",
    "    \"\"\"Load and average Amazon moisture recycling data.\"\"\"\n",
    "    all_rain = []\n",
    "    all_evap = []\n",
    "    all_network = []\n",
    "    \n",
    "    for month in months:\n",
    "        file_path = DATA_PATH / f'1deg_{year}_{month:02d}.nc'\n",
    "        if file_path.exists():\n",
    "            with Dataset(file_path, 'r') as ds:\n",
    "                all_rain.append(ds.variables['rain'][:])\n",
    "                all_evap.append(ds.variables['evap'][:])\n",
    "                all_network.append(ds.variables['network'][:])\n",
    "    \n",
    "    return {\n",
    "        'rain': np.mean(all_rain, axis=0),\n",
    "        'evap': np.mean(all_evap, axis=0),\n",
    "        'network': np.mean(all_network, axis=0),\n",
    "        'n_cells': len(all_rain[0])\n",
    "    }\n",
    "\n",
    "amazon_data = load_amazon_data(year=2003)\n",
    "network_matrix = amazon_data['network']\n",
    "print(f\"Loaded Amazon data: {amazon_data['n_cells']} cells\")\n",
    "print(f\"Network shape: {network_matrix.shape}\")\n",
    "print(f\"Total moisture flow: {network_matrix.sum():.1f} mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'n_cells': 50,\n",
    "    'min_flow': 1.0,\n",
    "    'barrier_height': 0.2,\n",
    "    'cascade_duration': 200,\n",
    "    'recovery_duration': 800,\n",
    "    'dt': 0.5,\n",
    "    'cascade_sigma': 0.06,\n",
    "    'cascade_alpha': 1.5,\n",
    "    'recovery_sigma': 0.04,\n",
    "    'recovery_alpha': 2.0,\n",
    "    'n_runs': 20,\n",
    "    'base_seed': 42,\n",
    "}\n",
    "\n",
    "# Connectivity levels to test\n",
    "CONNECTIVITY_LEVELS = [0.01, 0.02, 0.05, 0.10, 0.15, 0.20, 0.25, 0.50, 0.75, 1.00]\n",
    "\n",
    "# Fragmentation strategies\n",
    "STRATEGIES = ['random', 'keystone_preserve', 'keystone_remove']\n",
    "\n",
    "# Keystone edges from Experiment 12\n",
    "KEYSTONE_EDGES = [\n",
    "    ('cell_28', 'cell_14'),  # Most critical: -7.9% recovery impact\n",
    "    ('cell_27', 'cell_12'),\n",
    "    ('cell_32', 'cell_40'),\n",
    "    ('cell_31', 'cell_4'),\n",
    "    ('cell_17', 'cell_32'),\n",
    "    ('cell_31', 'cell_24'),\n",
    "]\n",
    "\n",
    "print(f\"Connectivity levels: {CONNECTIVITY_LEVELS}\")\n",
    "print(f\"Strategies: {STRATEGIES}\")\n",
    "print(f\"Runs per condition: {CONFIG['n_runs']}\")\n",
    "print(f\"Total simulations: {len(CONNECTIVITY_LEVELS) * len(STRATEGIES) * CONFIG['n_runs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_connectivity_experiment(data_bytes, connectivity, strategy, keystone_edges, config, seed):\n",
    "    \"\"\"\n",
    "    Worker function for connectivity threshold experiment.\n",
    "    Uses run_two_phase_experiment from solvers module.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import sys\n",
    "    \n",
    "    if '/opt/research-local/src' not in sys.path:\n",
    "        sys.path.insert(0, '/opt/research-local/src')\n",
    "    \n",
    "    from energy_constrained import (\n",
    "        EnergyConstrainedNetwork,\n",
    "        EnergyConstrainedCusp,\n",
    "        GradientDrivenCoupling,\n",
    "    )\n",
    "    from energy_constrained.solvers import run_two_phase_experiment\n",
    "    \n",
    "    # Deserialize data\n",
    "    data = pickle.loads(data_bytes)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    # Extract parameters\n",
    "    network_matrix = data['network']\n",
    "    n_cells = config['n_cells']\n",
    "    min_flow = config['min_flow']\n",
    "    barrier_height = config['barrier_height']\n",
    "    \n",
    "    # Select top cells by total flow\n",
    "    total_flow = network_matrix.sum(axis=0) + network_matrix.sum(axis=1)\n",
    "    top_indices = np.argsort(total_flow)[-n_cells:]\n",
    "    \n",
    "    # Build network\n",
    "    net = EnergyConstrainedNetwork()\n",
    "    \n",
    "    # Add elements\n",
    "    for i in range(n_cells):\n",
    "        element = EnergyConstrainedCusp(\n",
    "            a=-1.0, b=1.0, c=0.0, x_0=0.0,\n",
    "            barrier_height=barrier_height,\n",
    "            dissipation_rate=0.1\n",
    "        )\n",
    "        net.add_element(f'cell_{i}', element)\n",
    "    \n",
    "    # Build all possible edges\n",
    "    all_edges = {}\n",
    "    for i, idx_i in enumerate(top_indices):\n",
    "        for j, idx_j in enumerate(top_indices):\n",
    "            if i != j:\n",
    "                flow = network_matrix[idx_i, idx_j]\n",
    "                if flow > min_flow:\n",
    "                    all_edges[(f'cell_{i}', f'cell_{j}')] = flow\n",
    "    \n",
    "    total_edges = len(all_edges)\n",
    "    n_keep = max(1, int(total_edges * connectivity))\n",
    "    \n",
    "    # Convert keystone edges to set for fast lookup\n",
    "    keystone_set = set(tuple(e) for e in keystone_edges)\n",
    "    non_keystone_edges = [e for e in all_edges.keys() if e not in keystone_set]\n",
    "    keystone_in_network = [e for e in keystone_edges if tuple(e) in all_edges]\n",
    "    \n",
    "    # Select edges based on strategy\n",
    "    if strategy == 'random':\n",
    "        all_edge_list = list(all_edges.keys())\n",
    "        rng.shuffle(all_edge_list)\n",
    "        edges_to_keep = all_edge_list[:n_keep]\n",
    "        \n",
    "    elif strategy == 'keystone_preserve':\n",
    "        # Always include keystones (up to n_keep)\n",
    "        edges_to_keep = list(keystone_in_network[:min(len(keystone_in_network), n_keep)])\n",
    "        remaining = n_keep - len(edges_to_keep)\n",
    "        if remaining > 0:\n",
    "            non_keystone_list = list(non_keystone_edges)\n",
    "            rng.shuffle(non_keystone_list)\n",
    "            edges_to_keep.extend(non_keystone_list[:remaining])\n",
    "            \n",
    "    elif strategy == 'keystone_remove':\n",
    "        # Exclude keystones\n",
    "        available = list(non_keystone_edges)\n",
    "        rng.shuffle(available)\n",
    "        edges_to_keep = available[:min(len(available), n_keep)]\n",
    "    \n",
    "    edges_set = set(tuple(e) for e in edges_to_keep)\n",
    "    \n",
    "    # Count keystone edges in final selection\n",
    "    n_keystone_kept = sum(1 for e in keystone_in_network if tuple(e) in edges_set)\n",
    "    \n",
    "    # Add couplings for kept edges\n",
    "    n_edges_added = 0\n",
    "    for (src, tgt), flow in all_edges.items():\n",
    "        if (src, tgt) in edges_set:\n",
    "            coupling = GradientDrivenCoupling(\n",
    "                conductivity=flow / 100.0,\n",
    "                state_coupling=0.1\n",
    "            )\n",
    "            net.add_coupling(src, tgt, coupling)\n",
    "            n_edges_added += 1\n",
    "    \n",
    "    # Run two-phase experiment\n",
    "    result = run_two_phase_experiment(\n",
    "        network=net,\n",
    "        cascade_duration=config['cascade_duration'],\n",
    "        recovery_duration=config['recovery_duration'],\n",
    "        dt=config['dt'],\n",
    "        cascade_sigma=config['cascade_sigma'],\n",
    "        cascade_alpha=config['cascade_alpha'],\n",
    "        recovery_sigma=config['recovery_sigma'],\n",
    "        recovery_alpha=config['recovery_alpha'],\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    # Extract metrics\n",
    "    n_cells_actual = result.x_full.shape[1]\n",
    "    n_tip_events = 0\n",
    "    n_recover_events = 0\n",
    "    \n",
    "    for j in range(n_cells_actual):\n",
    "        x_traj = result.x_full[:, j]\n",
    "        signs = np.sign(x_traj)\n",
    "        sign_changes = np.diff(signs)\n",
    "        n_tip_events += np.sum(sign_changes > 0)\n",
    "        n_recover_events += np.sum(sign_changes < 0)\n",
    "    \n",
    "    tip_recovery_ratio = n_tip_events / n_recover_events if n_recover_events > 0 else np.nan\n",
    "    \n",
    "    return {\n",
    "        'connectivity': connectivity,\n",
    "        'strategy': strategy,\n",
    "        'n_edges': n_edges_added,\n",
    "        'n_keystone_edges': n_keystone_kept,\n",
    "        'total_possible_edges': total_edges,\n",
    "        'seed': seed,\n",
    "        'pct_tipped_cascade': result.metrics['pct_tipped_at_cascade_end'],\n",
    "        'final_pct_tipped': result.metrics['final_pct_tipped'],\n",
    "        'recovery_fraction': result.metrics['recovery_fraction'],\n",
    "        'n_tip_events': n_tip_events,\n",
    "        'n_recover_events': n_recover_events,\n",
    "        'tip_recovery_ratio': tip_recovery_ratio,\n",
    "        'n_permanent_tips': result.metrics['n_permanent_tips'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for workers\n",
    "data_bytes = pickle.dumps(amazon_data)\n",
    "\n",
    "# Scatter data to workers\n",
    "data_future = client.scatter(data_bytes, broadcast=True)\n",
    "print(f\"Data scattered to workers: {len(data_bytes) / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit all tasks\n",
    "start_time = time.time()\n",
    "\n",
    "futures = []\n",
    "task_info = []\n",
    "\n",
    "for connectivity in CONNECTIVITY_LEVELS:\n",
    "    for strategy in STRATEGIES:\n",
    "        for run_idx in range(CONFIG['n_runs']):\n",
    "            seed = CONFIG['base_seed'] + run_idx + int(connectivity * 1000) + hash(strategy) % 1000\n",
    "            \n",
    "            future = client.submit(\n",
    "                run_connectivity_experiment,\n",
    "                data_future,\n",
    "                connectivity,\n",
    "                strategy,\n",
    "                KEYSTONE_EDGES,\n",
    "                CONFIG,\n",
    "                seed,\n",
    "                pure=False\n",
    "            )\n",
    "            futures.append(future)\n",
    "            task_info.append((connectivity, strategy, run_idx))\n",
    "\n",
    "print(f\"Submitted {len(futures)} tasks\")\n",
    "print(f\"Conditions: {len(CONNECTIVITY_LEVELS)} connectivity × {len(STRATEGIES)} strategies × {CONFIG['n_runs']} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect results with progress tracking\n",
    "results = []\n",
    "completed = 0\n",
    "errors = 0\n",
    "\n",
    "for future in as_completed(futures):\n",
    "    try:\n",
    "        result = future.result()\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        errors += 1\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    completed += 1\n",
    "    if completed % 50 == 0 or completed == len(futures):\n",
    "        elapsed = time.time() - start_time\n",
    "        rate = completed / elapsed\n",
    "        eta = (len(futures) - completed) / rate if rate > 0 else 0\n",
    "        print(f\"Progress: {completed}/{len(futures)} ({100*completed/len(futures):.1f}%) - \"\n",
    "              f\"Elapsed: {elapsed/60:.1f}m - ETA: {eta/60:.1f}m\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nCompleted in {total_time/60:.1f} minutes\")\n",
    "print(f\"Successful: {len(results)}, Errors: {errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "print(f\"Results shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by connectivity and strategy\n",
    "summary = df.groupby(['connectivity', 'strategy']).agg({\n",
    "    'recovery_fraction': ['mean', 'std', 'count'],\n",
    "    'n_edges': 'mean',\n",
    "    'n_keystone_edges': 'mean',\n",
    "    'pct_tipped_cascade': 'mean',\n",
    "    'tip_recovery_ratio': 'mean',\n",
    "    'n_permanent_tips': 'mean',\n",
    "}).round(4)\n",
    "\n",
    "summary.columns = ['_'.join(col).strip() for col in summary.columns.values]\n",
    "summary = summary.reset_index()\n",
    "print(summary.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot for easier plotting\n",
    "pivot_recovery = df.pivot_table(\n",
    "    values='recovery_fraction',\n",
    "    index='connectivity',\n",
    "    columns='strategy',\n",
    "    aggfunc=['mean', 'std']\n",
    ")\n",
    "\n",
    "print(\"Recovery Fraction by Connectivity and Strategy:\")\n",
    "print(pivot_recovery.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 12c.1: Recovery fraction vs connectivity (3 curves)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = {'random': 'blue', 'keystone_preserve': 'green', 'keystone_remove': 'red'}\n",
    "labels = {'random': 'Random', 'keystone_preserve': 'Keystone Preserve', 'keystone_remove': 'Keystone Remove'}\n",
    "\n",
    "for strategy in STRATEGIES:\n",
    "    data = df[df['strategy'] == strategy].groupby('connectivity')['recovery_fraction'].agg(['mean', 'std'])\n",
    "    \n",
    "    ax.errorbar(\n",
    "        data.index * 100,  # Convert to percentage\n",
    "        data['mean'] * 100,  # Convert to percentage\n",
    "        yerr=data['std'] * 100,\n",
    "        label=labels[strategy],\n",
    "        color=colors[strategy],\n",
    "        marker='o',\n",
    "        capsize=3,\n",
    "        linewidth=2,\n",
    "        markersize=8\n",
    "    )\n",
    "\n",
    "ax.axhline(y=10, color='gray', linestyle='--', alpha=0.5, label='10% threshold')\n",
    "ax.set_xlabel('Connectivity (%)', fontsize=12)\n",
    "ax.set_ylabel('Recovery Fraction (%)', fontsize=12)\n",
    "ax.set_title('Experiment 12c: Recovery vs Network Connectivity', fontsize=14)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(-2, 105)\n",
    "ax.set_ylim(-2, 50)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/workspace/data/exp12c_recovery_vs_connectivity.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 12c.2: Keystone benefit (preserve - random) vs connectivity\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "random_recovery = df[df['strategy'] == 'random'].groupby('connectivity')['recovery_fraction'].mean()\n",
    "preserve_recovery = df[df['strategy'] == 'keystone_preserve'].groupby('connectivity')['recovery_fraction'].mean()\n",
    "remove_recovery = df[df['strategy'] == 'keystone_remove'].groupby('connectivity')['recovery_fraction'].mean()\n",
    "\n",
    "benefit_preserve = (preserve_recovery - random_recovery) * 100\n",
    "benefit_remove = (remove_recovery - random_recovery) * 100\n",
    "\n",
    "ax.bar(np.array(benefit_preserve.index) * 100 - 1.5, benefit_preserve.values, \n",
    "       width=3, color='green', alpha=0.7, label='Keystone Preserve - Random')\n",
    "ax.bar(np.array(benefit_remove.index) * 100 + 1.5, benefit_remove.values, \n",
    "       width=3, color='red', alpha=0.7, label='Keystone Remove - Random')\n",
    "\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax.set_xlabel('Connectivity (%)', fontsize=12)\n",
    "ax.set_ylabel('Recovery Difference (percentage points)', fontsize=12)\n",
    "ax.set_title('Keystone Effect: Benefit of Preserving vs Removing Keystones', fontsize=14)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/workspace/data/exp12c_keystone_benefit.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 12c.3: Tip/recovery ratio vs connectivity\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "for strategy in STRATEGIES:\n",
    "    data = df[df['strategy'] == strategy].groupby('connectivity')['tip_recovery_ratio'].mean()\n",
    "    ax.plot(data.index * 100, data.values, \n",
    "            label=labels[strategy], color=colors[strategy], \n",
    "            marker='o', linewidth=2, markersize=6)\n",
    "\n",
    "ax.axhline(y=1.0, color='gray', linestyle='--', alpha=0.5, label='Balanced (ratio=1)')\n",
    "ax.set_xlabel('Connectivity (%)', fontsize=12)\n",
    "ax.set_ylabel('Tip/Recovery Ratio', fontsize=12)\n",
    "ax.set_title('Asymmetry: Tip/Recovery Ratio vs Connectivity', fontsize=14)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/workspace/data/exp12c_asymmetry.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold analysis: Find connectivity where recovery crosses 10%\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def find_threshold(connectivity, recovery, target=0.10):\n",
    "    \"\"\"Find connectivity level where recovery crosses target.\"\"\"\n",
    "    # Sort by connectivity\n",
    "    idx = np.argsort(connectivity)\n",
    "    conn_sorted = np.array(connectivity)[idx]\n",
    "    rec_sorted = np.array(recovery)[idx]\n",
    "    \n",
    "    # Find crossing point\n",
    "    for i in range(len(rec_sorted) - 1):\n",
    "        if rec_sorted[i] < target <= rec_sorted[i+1]:\n",
    "            # Linear interpolation\n",
    "            t = (target - rec_sorted[i]) / (rec_sorted[i+1] - rec_sorted[i])\n",
    "            return conn_sorted[i] + t * (conn_sorted[i+1] - conn_sorted[i])\n",
    "    \n",
    "    return None\n",
    "\n",
    "print(\"=== Threshold Analysis ===\")\n",
    "print(\"\\nConnectivity where recovery crosses 10%:\")\n",
    "\n",
    "for strategy in STRATEGIES:\n",
    "    data = df[df['strategy'] == strategy].groupby('connectivity')['recovery_fraction'].mean()\n",
    "    threshold = find_threshold(data.index.tolist(), data.values.tolist(), target=0.10)\n",
    "    if threshold:\n",
    "        print(f\"  {labels[strategy]}: {threshold*100:.1f}%\")\n",
    "    else:\n",
    "        print(f\"  {labels[strategy]}: Not reached\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap confidence intervals for threshold\n",
    "def bootstrap_threshold(df_strategy, target=0.10, n_bootstrap=1000):\n",
    "    \"\"\"Bootstrap 95% CI for threshold.\"\"\"\n",
    "    thresholds = []\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        # Resample with replacement\n",
    "        sample = df_strategy.groupby('connectivity').apply(\n",
    "            lambda x: x.sample(n=len(x), replace=True)\n",
    "        ).reset_index(drop=True)\n",
    "        \n",
    "        # Compute mean recovery per connectivity\n",
    "        means = sample.groupby('connectivity')['recovery_fraction'].mean()\n",
    "        \n",
    "        # Find threshold\n",
    "        threshold = find_threshold(means.index.tolist(), means.values.tolist(), target=target)\n",
    "        if threshold is not None:\n",
    "            thresholds.append(threshold)\n",
    "    \n",
    "    if len(thresholds) > 0:\n",
    "        return np.percentile(thresholds, [2.5, 50, 97.5])\n",
    "    return None\n",
    "\n",
    "print(\"\\n=== Bootstrap 95% CI for 10% Recovery Threshold ===\")\n",
    "for strategy in STRATEGIES:\n",
    "    df_strat = df[df['strategy'] == strategy]\n",
    "    ci = bootstrap_threshold(df_strat, target=0.10, n_bootstrap=500)\n",
    "    if ci is not None:\n",
    "        print(f\"{labels[strategy]}: {ci[1]*100:.1f}% [{ci[0]*100:.1f}%, {ci[2]*100:.1f}%]\")\n",
    "    else:\n",
    "        print(f\"{labels[strategy]}: Threshold not reached in bootstrap samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENT 12c: KEY FINDINGS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Reference values\n",
    "full_network = df[df['connectivity'] == 1.0]['recovery_fraction'].mean()\n",
    "print(f\"\\nFull network (100% connectivity): {full_network*100:.1f}% recovery\")\n",
    "\n",
    "print(\"\\n--- Recovery by Connectivity Level ---\")\n",
    "print(f\"{'Connectivity':>12} | {'Random':>10} | {'Preserve':>10} | {'Remove':>10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for conn in CONNECTIVITY_LEVELS:\n",
    "    random_rec = df[(df['connectivity'] == conn) & (df['strategy'] == 'random')]['recovery_fraction'].mean()\n",
    "    preserve_rec = df[(df['connectivity'] == conn) & (df['strategy'] == 'keystone_preserve')]['recovery_fraction'].mean()\n",
    "    remove_rec = df[(df['connectivity'] == conn) & (df['strategy'] == 'keystone_remove')]['recovery_fraction'].mean()\n",
    "    print(f\"{conn*100:>10.0f}% | {random_rec*100:>9.1f}% | {preserve_rec*100:>9.1f}% | {remove_rec*100:>9.1f}%\")\n",
    "\n",
    "print(\"\\n--- Keystone Effect Summary ---\")\n",
    "avg_benefit_preserve = benefit_preserve.mean()\n",
    "avg_benefit_remove = benefit_remove.mean()\n",
    "print(f\"Average benefit of keystone preservation: {avg_benefit_preserve:+.1f} percentage points\")\n",
    "print(f\"Average impact of keystone removal: {avg_benefit_remove:+.1f} percentage points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "output_path = '/workspace/data/experiment12c_results.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Results saved to {output_path}\")\n",
    "\n",
    "# Also save summary\n",
    "summary_path = '/workspace/data/experiment12c_summary.csv'\n",
    "summary.to_csv(summary_path, index=False)\n",
    "print(f\"Summary saved to {summary_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "### 1. Connectivity Threshold\n",
    "- **Minimum connectivity for >10% recovery**: [TBD after running]\n",
    "- **Transition type**: Sharp or gradual [TBD]\n",
    "\n",
    "### 2. Keystone Effect\n",
    "- **Benefit of keystone preservation**: [TBD]\n",
    "- **Cost of keystone removal**: [TBD]\n",
    "- **Effect magnitude at different connectivity levels**: [TBD]\n",
    "\n",
    "### 3. Conservation Implications\n",
    "- Minimum viable network density: [TBD]\n",
    "- Value of keystone protection: [TBD]\n",
    "- Recommended conservation strategy: [TBD]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
