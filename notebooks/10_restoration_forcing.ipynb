{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Experiment 10c: Restoration Forcing Sweep\n",
    "\n",
    "**Phase 4 - Quantifying Active Intervention Requirements**\n",
    "\n",
    "## Background\n",
    "\n",
    "Experiments 10 and 10b demonstrated that **passive recovery is impossible** under any tested noise regime:\n",
    "- Varying α (1.1-2.0): ~1.3% recovery\n",
    "- Varying σ (0.04-0.12): ~0-4% recovery\n",
    "- Best case (α=1.2, σ=0.10): only 3.6% recovery\n",
    "\n",
    "**Key insight**: The barrier height creates insurmountable hysteresis - noise alone cannot push cells from the tipped attractor back to the stable state.\n",
    "\n",
    "## This Experiment\n",
    "\n",
    "Add **restoration forcing** during recovery phase - a constant negative term in dx/dt that pushes cells toward the stable state (x < 0). This models:\n",
    "- Reforestation programs\n",
    "- Fire suppression efforts\n",
    "- Moisture corridor restoration\n",
    "- Active ecosystem management\n",
    "\n",
    "The forcing term adds `f` to dx/dt during recovery:\n",
    "```\n",
    "dx/dt = cusp_dynamics + coupling + f\n",
    "```\n",
    "where `f < 0` pushes toward stable state.\n",
    "\n",
    "## Experimental Design\n",
    "\n",
    "| Parameter | Values |\n",
    "|-----------|--------|\n",
    "| Forcing strength | [0.0, -0.05, -0.10, -0.15, -0.20, -0.30, -0.40, -0.50] |\n",
    "| Recovery α | 2.0 (Gaussian - conservative) |\n",
    "| Recovery σ | 0.04 (baseline from Exp 9) |\n",
    "| Ensemble runs | 20 per forcing level |\n",
    "| **Total simulations** | 160 |\n",
    "\n",
    "## Research Questions\n",
    "\n",
    "1. What forcing strength is needed for >50% recovery?\n",
    "2. Is the forcing-recovery relationship linear or threshold-like?\n",
    "3. How does forcing interact with noise?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/opt/research-local/src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "from netCDF4 import Dataset\n",
    "from dask.distributed import as_completed\n",
    "\n",
    "# Core energy-constrained module\n",
    "from energy_constrained import (\n",
    "    EnergyConstrainedNetwork,\n",
    "    EnergyConstrainedCusp,\n",
    "    GradientDrivenCoupling,\n",
    "    run_two_phase_experiment,\n",
    "    get_dask_client\n",
    ")\n",
    "\n",
    "print(\"Imports successful!\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dask-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Dask cluster\n",
    "client = get_dask_client()\n",
    "print(f\"Connected to: {client.scheduler_info()['address']}\")\n",
    "print(f\"Workers: {len(client.scheduler_info()['workers'])}\")\n",
    "print(f\"Total threads: {sum(w['nthreads'] for w in client.scheduler_info()['workers'].values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## 2. Load Amazon Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('/opt/research-local/data/amazon/amazon_adaptation_model/average_network/era5_new_network_data')\n",
    "\n",
    "def load_amazon_data(year=2003, months=[7, 8, 9]):\n",
    "    \"\"\"Load and average Amazon moisture recycling data.\"\"\"\n",
    "    all_rain = []\n",
    "    all_evap = []\n",
    "    all_network = []\n",
    "    \n",
    "    for month in months:\n",
    "        file_path = DATA_PATH / f'1deg_{year}_{month:02d}.nc'\n",
    "        if file_path.exists():\n",
    "            with Dataset(file_path, 'r') as ds:\n",
    "                all_rain.append(ds.variables['rain'][:])\n",
    "                all_evap.append(ds.variables['evap'][:])\n",
    "                all_network.append(ds.variables['network'][:])\n",
    "    \n",
    "    return {\n",
    "        'rain': np.mean(all_rain, axis=0),\n",
    "        'evap': np.mean(all_evap, axis=0),\n",
    "        'network': np.mean(all_network, axis=0),\n",
    "        'n_cells': len(all_rain[0])\n",
    "    }\n",
    "\n",
    "amazon_data = load_amazon_data(year=2003)\n",
    "print(f\"Loaded Amazon data: {amazon_data['n_cells']} cells\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 3. Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 10c: Restoration Forcing Sweep\n",
    "\n",
    "SWEEP_CONFIG = {\n",
    "    # Forcing sweep - negative values push toward stable state\n",
    "    'forcing_values': np.array([0.0, -0.05, -0.10, -0.15, -0.20, -0.30, -0.40, -0.50]),\n",
    "    'n_runs_per_forcing': 20,\n",
    "    \n",
    "    # Network parameters\n",
    "    'n_cells': 50,\n",
    "    'min_flow': 1.0,\n",
    "    'barrier_height': 0.2,\n",
    "    \n",
    "    # Two-phase simulation parameters\n",
    "    'cascade_duration': 200,\n",
    "    'recovery_duration': 800,\n",
    "    'dt': 0.5,\n",
    "    'cascade_sigma': 0.06,\n",
    "    'cascade_alpha': 1.5,\n",
    "    'recovery_sigma': 0.04,  # Baseline from Exp 9\n",
    "    'recovery_alpha': 2.0,   # Gaussian (conservative)\n",
    "    \n",
    "    # Seeds\n",
    "    'base_seed': 42,\n",
    "}\n",
    "\n",
    "n_forcing = len(SWEEP_CONFIG['forcing_values'])\n",
    "total_sims = n_forcing * SWEEP_CONFIG['n_runs_per_forcing']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 10c: RESTORATION FORCING SWEEP\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Forcing values: {SWEEP_CONFIG['forcing_values']}\")\n",
    "print(f\"Runs per forcing level: {SWEEP_CONFIG['n_runs_per_forcing']}\")\n",
    "print(f\"Total simulations: {total_sims}\")\n",
    "print(f\"\\nRecovery parameters (fixed):\")\n",
    "print(f\"  α = {SWEEP_CONFIG['recovery_alpha']} (Gaussian)\")\n",
    "print(f\"  σ = {SWEEP_CONFIG['recovery_sigma']}\")\n",
    "print(f\"\\nPhysical interpretation:\")\n",
    "print(f\"  f=0.0:  No intervention (passive recovery)\")\n",
    "print(f\"  f=-0.1: Moderate intervention\")\n",
    "print(f\"  f=-0.3: Strong intervention\")\n",
    "print(f\"  f=-0.5: Maximum intervention\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "network-header",
   "metadata": {},
   "source": [
    "## 4. Network Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "network-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sweep_network(data, config, seed=42):\n",
    "    \"\"\"Create 50-cell network for forcing sweep.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    network_matrix = data['network']\n",
    "    n_cells = config['n_cells']\n",
    "    min_flow = config['min_flow']\n",
    "    barrier_height = config['barrier_height']\n",
    "    \n",
    "    total_flow = network_matrix.sum(axis=0) + network_matrix.sum(axis=1)\n",
    "    top_indices = np.argsort(total_flow)[-n_cells:]\n",
    "    \n",
    "    net = EnergyConstrainedNetwork()\n",
    "    \n",
    "    for i, idx in enumerate(top_indices):\n",
    "        element = EnergyConstrainedCusp(\n",
    "            a=-1.0, b=1.0, c=0.0, x_0=0.0,\n",
    "            barrier_height=barrier_height,\n",
    "            dissipation_rate=0.1\n",
    "        )\n",
    "        net.add_element(f'cell_{i}', element)\n",
    "    \n",
    "    n_edges = 0\n",
    "    for i, idx_i in enumerate(top_indices):\n",
    "        for j, idx_j in enumerate(top_indices):\n",
    "            if i != j:\n",
    "                flow = network_matrix[idx_i, idx_j]\n",
    "                if flow > min_flow:\n",
    "                    coupling = GradientDrivenCoupling(\n",
    "                        conductivity=flow / 100.0,\n",
    "                        state_coupling=0.1\n",
    "                    )\n",
    "                    net.add_coupling(f'cell_{i}', f'cell_{j}', coupling)\n",
    "                    n_edges += 1\n",
    "    \n",
    "    return net, top_indices\n",
    "\n",
    "network, selected_cells = create_sweep_network(amazon_data, SWEEP_CONFIG)\n",
    "print(f\"Created network: {network.n_elements} nodes, {network.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worker-header",
   "metadata": {},
   "source": [
    "## 5. Worker Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worker-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_forcing_experiment(args):\n",
    "    \"\"\"\n",
    "    Worker function for a single forcing experiment.\n",
    "    \"\"\"\n",
    "    network_bytes, recovery_forcing, config, seed = args\n",
    "    \n",
    "    import sys\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    \n",
    "    if '/opt/research-local/src' not in sys.path:\n",
    "        sys.path.insert(0, '/opt/research-local/src')\n",
    "    \n",
    "    from energy_constrained.solvers import run_two_phase_experiment\n",
    "    \n",
    "    network = pickle.loads(network_bytes)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Run with forcing\n",
    "    result = run_two_phase_experiment(\n",
    "        network=network,\n",
    "        cascade_duration=config['cascade_duration'],\n",
    "        recovery_duration=config['recovery_duration'],\n",
    "        dt=config['dt'],\n",
    "        cascade_sigma=config['cascade_sigma'],\n",
    "        cascade_alpha=config['cascade_alpha'],\n",
    "        recovery_sigma=config['recovery_sigma'],\n",
    "        recovery_alpha=config['recovery_alpha'],\n",
    "        recovery_forcing=recovery_forcing,  # THE SWEEP VARIABLE\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    # Compute additional metrics\n",
    "    pct_time_tipped = np.mean(result.x_full > 0) * 100\n",
    "    \n",
    "    n_cells = result.x_full.shape[1]\n",
    "    n_tip_events = 0\n",
    "    n_recover_events = 0\n",
    "    \n",
    "    for j in range(n_cells):\n",
    "        x_traj = result.x_full[:, j]\n",
    "        signs = np.sign(x_traj)\n",
    "        sign_changes = np.diff(signs)\n",
    "        n_tip_events += np.sum(sign_changes > 0)\n",
    "        n_recover_events += np.sum(sign_changes < 0)\n",
    "    \n",
    "    return {\n",
    "        'recovery_forcing': recovery_forcing,\n",
    "        'seed': seed,\n",
    "        'recovery_fraction': result.metrics['recovery_fraction'],\n",
    "        'pct_tipped_cascade': result.metrics['pct_tipped_at_cascade_end'],\n",
    "        'n_permanent_tips': result.metrics['n_permanent_tips'],\n",
    "        'final_pct_tipped': result.metrics['final_pct_tipped'],\n",
    "        'pct_time_tipped': pct_time_tipped,\n",
    "        'n_tip_events': n_tip_events,\n",
    "        'n_recover_events': n_recover_events,\n",
    "        'mean_recovery_time': result.metrics['mean_recovery_time'],\n",
    "    }\n",
    "\n",
    "print(\"Worker function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run-header",
   "metadata": {},
   "source": [
    "## 6. Run Forcing Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize and scatter network\n",
    "network_bytes = pickle.dumps(network)\n",
    "print(f\"Network serialized: {len(network_bytes) / 1024:.1f} KB\")\n",
    "\n",
    "network_future = client.scatter(network_bytes, broadcast=True)\n",
    "print(\"Network broadcast to all workers\")\n",
    "\n",
    "# Build task arguments\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPERIMENT 10c: Starting Forcing Sweep\")\n",
    "print(\"=\" * 60)\n",
    "start_time = time.time()\n",
    "\n",
    "task_args = []\n",
    "for i, forcing in enumerate(SWEEP_CONFIG['forcing_values']):\n",
    "    for run_idx in range(SWEEP_CONFIG['n_runs_per_forcing']):\n",
    "        seed = SWEEP_CONFIG['base_seed'] + i * 1000 + run_idx\n",
    "        task_args.append((network_bytes, float(forcing), SWEEP_CONFIG, seed))\n",
    "\n",
    "print(f\"Generated {len(task_args)} task arguments\")\n",
    "\n",
    "# Submit using client.map\n",
    "futures = client.map(run_single_forcing_experiment, task_args)\n",
    "print(f\"Submitted {len(futures)} tasks\")\n",
    "\n",
    "# Collect results\n",
    "all_results = []\n",
    "print(\"\\nProgress:\")\n",
    "\n",
    "for i, future in enumerate(as_completed(futures)):\n",
    "    result = future.result()\n",
    "    all_results.append(result)\n",
    "    \n",
    "    if (i + 1) % 20 == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"  Completed {i+1}/{len(futures)} ({100*(i+1)/len(futures):.1f}%)\")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"COMPLETE: {len(all_results)} simulations in {elapsed:.1f}s ({elapsed/60:.1f} min)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-header",
   "metadata": {},
   "source": [
    "## 7. Results Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results-df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_results)\n",
    "print(f\"Results shape: {df.shape}\")\n",
    "\n",
    "df = df.sort_values(['recovery_forcing', 'seed']).reset_index(drop=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics by forcing level\n",
    "summary = df.groupby('recovery_forcing').agg({\n",
    "    'recovery_fraction': ['mean', 'std', 'min', 'max'],\n",
    "    'n_permanent_tips': ['mean', 'std'],\n",
    "    'final_pct_tipped': ['mean', 'std'],\n",
    "    'mean_recovery_time': ['mean', 'std'],\n",
    "    'n_recover_events': ['mean', 'std'],\n",
    "}).round(4)\n",
    "\n",
    "summary.columns = ['_'.join(col) for col in summary.columns]\n",
    "summary = summary.reset_index()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FORCING SWEEP SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(summary[['recovery_forcing', 'recovery_fraction_mean', 'recovery_fraction_std',\n",
    "               'n_permanent_tips_mean', 'mean_recovery_time_mean']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "## 8. Primary Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-forcing",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "forcing_vals = summary['recovery_forcing'].values\n",
    "\n",
    "# Panel 1: Recovery Fraction vs Forcing (KEY RESULT)\n",
    "ax = axes[0, 0]\n",
    "means = summary['recovery_fraction_mean'].values\n",
    "stds = summary['recovery_fraction_std'].values\n",
    "ax.errorbar(-forcing_vals, means, yerr=stds, marker='o', capsize=4, \n",
    "            linewidth=2, markersize=10, color='green')\n",
    "ax.axhline(0.5, color='orange', linestyle='--', alpha=0.7, linewidth=2, label='50% recovery')\n",
    "ax.axhline(0.1, color='red', linestyle=':', alpha=0.7, linewidth=2, label='10% recovery')\n",
    "ax.set_xlabel('Restoration Forcing Strength (|f|)', fontsize=12)\n",
    "ax.set_ylabel('Recovery Fraction', fontsize=12)\n",
    "ax.set_title('Recovery vs Restoration Forcing', fontsize=14)\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: Permanent Tips vs Forcing\n",
    "ax = axes[0, 1]\n",
    "means = summary['n_permanent_tips_mean'].values\n",
    "stds = summary['n_permanent_tips_std'].values\n",
    "ax.errorbar(-forcing_vals, means, yerr=stds, marker='s', capsize=4,\n",
    "            linewidth=2, markersize=10, color='red')\n",
    "ax.set_xlabel('Restoration Forcing Strength (|f|)', fontsize=12)\n",
    "ax.set_ylabel('Permanent Tips (out of 50)', fontsize=12)\n",
    "ax.set_title('Irreversibility vs Restoration Forcing', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 3: Recovery Time vs Forcing\n",
    "ax = axes[1, 0]\n",
    "means = summary['mean_recovery_time_mean'].values\n",
    "stds = summary['mean_recovery_time_std'].values\n",
    "# Filter out NaN values for plotting\n",
    "valid_idx = ~np.isnan(means)\n",
    "if np.any(valid_idx):\n",
    "    ax.errorbar(-forcing_vals[valid_idx], means[valid_idx], yerr=stds[valid_idx],\n",
    "                marker='^', capsize=4, linewidth=2, markersize=10, color='blue')\n",
    "ax.set_xlabel('Restoration Forcing Strength (|f|)', fontsize=12)\n",
    "ax.set_ylabel('Mean Recovery Time', fontsize=12)\n",
    "ax.set_title('Recovery Speed vs Restoration Forcing', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 4: Box plot of recovery fraction by forcing\n",
    "ax = axes[1, 1]\n",
    "data_by_forcing = [df[df['recovery_forcing'] == f]['recovery_fraction'].values \n",
    "                   for f in SWEEP_CONFIG['forcing_values']]\n",
    "bp = ax.boxplot(data_by_forcing, \n",
    "                labels=[f'{-f:.2f}' for f in SWEEP_CONFIG['forcing_values']], \n",
    "                patch_artist=True)\n",
    "\n",
    "# Color boxes by recovery level\n",
    "colors = plt.cm.RdYlGn(np.linspace(0, 1, len(SWEEP_CONFIG['forcing_values'])))\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "ax.axhline(0.5, color='orange', linestyle='--', alpha=0.7)\n",
    "ax.set_xlabel('Restoration Forcing Strength (|f|)', fontsize=12)\n",
    "ax.set_ylabel('Recovery Fraction', fontsize=12)\n",
    "ax.set_title('Recovery Distribution by Forcing Level', fontsize=14)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/workspace/data/exp10c_forcing_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nPlot saved to /workspace/data/exp10c_forcing_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threshold-header",
   "metadata": {},
   "source": [
    "## 9. Critical Forcing Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "find-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_critical_forcing(summary_df, recovery_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Find minimum forcing needed to achieve recovery_threshold.\n",
    "    \"\"\"\n",
    "    # Sort by forcing (most negative first)\n",
    "    subset = summary_df.sort_values('recovery_forcing')\n",
    "    forcings = subset['recovery_forcing'].values\n",
    "    recoveries = subset['recovery_fraction_mean'].values\n",
    "    \n",
    "    # Find crossing point (recovery increasing as forcing becomes more negative)\n",
    "    for i in range(len(forcings) - 1):\n",
    "        if recoveries[i] >= recovery_threshold > recoveries[i+1]:\n",
    "            # Linear interpolation\n",
    "            slope = (recoveries[i+1] - recoveries[i]) / (forcings[i+1] - forcings[i])\n",
    "            if slope != 0:\n",
    "                critical = forcings[i] + (recovery_threshold - recoveries[i]) / slope\n",
    "                return critical\n",
    "    \n",
    "    # Check if always above or below\n",
    "    if recoveries.max() < recovery_threshold:\n",
    "        return None  # Never reaches threshold\n",
    "    elif recoveries.min() >= recovery_threshold:\n",
    "        return forcings.max()  # Even weakest forcing is enough\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CRITICAL FORCING ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for thresh in [0.10, 0.30, 0.50, 0.70, 0.90]:\n",
    "    critical = find_critical_forcing(summary, thresh)\n",
    "    if critical is not None:\n",
    "        print(f\"\\n{thresh*100:.0f}% recovery requires forcing: f = {critical:.3f} (|f| = {-critical:.3f})\")\n",
    "    else:\n",
    "        print(f\"\\n{thresh*100:.0f}% recovery: threshold not reached in tested range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpretation-header",
   "metadata": {},
   "source": [
    "## 10. Physical Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"PHYSICAL INTERPRETATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Compare forcing to barrier height\n",
    "barrier = SWEEP_CONFIG['barrier_height']\n",
    "print(f\"\\nBarrier height: {barrier}\")\n",
    "print(f\"\\nForcing as fraction of barrier:\")\n",
    "\n",
    "for forcing in SWEEP_CONFIG['forcing_values']:\n",
    "    if forcing != 0:\n",
    "        ratio = -forcing / barrier\n",
    "        recovery = summary[summary['recovery_forcing'] == forcing]['recovery_fraction_mean'].values[0]\n",
    "        print(f\"  f = {forcing:.2f}: |f|/barrier = {ratio:.1%}, recovery = {recovery:.1%}\")\n",
    "\n",
    "# Estimate real-world forcing\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"REAL-WORLD IMPLICATIONS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "The forcing term f represents the intensity of active restoration efforts:\n",
    "\n",
    "  |f| = 0.1: Moderate intervention\n",
    "    - Protected areas with fire suppression\n",
    "    - Sustainable forestry practices\n",
    "    - Local reforestation projects\n",
    "\n",
    "  |f| = 0.3: Strong intervention  \n",
    "    - Large-scale reforestation programs\n",
    "    - Moisture corridor restoration\n",
    "    - Regional conservation networks\n",
    "\n",
    "  |f| = 0.5: Maximum intervention\n",
    "    - Full ecosystem restoration\n",
    "    - Complete deforestation ban\n",
    "    - Massive investment in recovery\n",
    "\n",
    "The critical forcing threshold tells us the MINIMUM intervention\n",
    "intensity needed to achieve meaningful recovery.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "findings-header",
   "metadata": {},
   "source": [
    "## 11. Key Findings Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "findings",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\" * 70)\nprint(\"EXPERIMENT 10c: KEY FINDINGS\")\nprint(\"=\" * 70)\n\n# Find critical forcings\ncritical_50 = find_critical_forcing(summary, 0.50)\ncritical_10 = find_critical_forcing(summary, 0.10)\n\n# Best and worst cases\nbest = summary.loc[summary['recovery_fraction_mean'].idxmax()]\nworst = summary.loc[summary['recovery_fraction_mean'].idxmin()]\n\n# Format critical thresholds safely\ncrit_10_str = f\"{-critical_10:.3f}\" if critical_10 is not None else \"N/A (not reached)\"\ncrit_50_str = f\"{-critical_50:.3f}\" if critical_50 is not None else \"N/A (not reached)\"\n\nprint(f\"\"\"\n1. PASSIVE RECOVERY (f=0):\n   Recovery fraction: {summary[summary['recovery_forcing']==0]['recovery_fraction_mean'].values[0]:.3f}\n   Confirms Experiments 10/10b: passive recovery is impossible\n\n2. CRITICAL FORCING THRESHOLDS:\n   10% recovery requires: |f| >= {crit_10_str}\n   50% recovery requires: |f| >= {crit_50_str}\n\n3. BEST RECOVERY ACHIEVED:\n   Forcing: f = {best['recovery_forcing']:.2f}\n   Recovery fraction: {best['recovery_fraction_mean']:.3f}\n   Permanent tips: {best['n_permanent_tips_mean']:.1f}\n\n4. FORCING-RECOVERY RELATIONSHIP:\n\"\"\")\n\n# Analyze linearity\nforcings = summary['recovery_forcing'].values\nrecoveries = summary['recovery_fraction_mean'].values\n# Only fit non-zero forcings\nmask = forcings != 0\nif np.sum(mask) > 2:\n    slope, intercept = np.polyfit(-forcings[mask], recoveries[mask], 1)\n    print(f\"   Linear fit: recovery ≈ {slope:.2f} * |f| + {intercept:.3f}\")\n    print(f\"   Each 0.1 increase in |f| adds ~{slope*0.1:.1%} recovery\")"
  },
  {
   "cell_type": "markdown",
   "id": "save-header",
   "metadata": {},
   "source": [
    "## 12. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/workspace/data/experiment10c_forcing_results.csv', index=False)\n",
    "print(f\"Full results saved to /workspace/data/experiment10c_forcing_results.csv\")\n",
    "\n",
    "summary.to_csv('/workspace/data/experiment10c_summary.csv', index=False)\n",
    "print(f\"Summary saved to /workspace/data/experiment10c_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPERIMENT 10c COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "CONFIGURATION:\n",
    "- Forcing values: {list(SWEEP_CONFIG['forcing_values'])}\n",
    "- Runs per level: {SWEEP_CONFIG['n_runs_per_forcing']}\n",
    "- Total simulations: {len(df)}\n",
    "- Runtime: {elapsed:.1f}s ({elapsed/60:.1f} min)\n",
    "\n",
    "FILES GENERATED:\n",
    "- /workspace/data/experiment10c_forcing_results.csv\n",
    "- /workspace/data/experiment10c_summary.csv  \n",
    "- /workspace/data/exp10c_forcing_results.png\n",
    "\n",
    "KEY CONCLUSION:\n",
    "Recovery from tipping requires active intervention (forcing).\n",
    "The critical forcing threshold quantifies the minimum restoration\n",
    "effort needed to reverse ecosystem collapse.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}